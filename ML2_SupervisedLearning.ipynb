{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d910cf18",
   "metadata": {},
   "source": [
    "### 1. Answer the questions  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e09ab4",
   "metadata": {},
   "source": [
    "1. Derive an analytical solution to the regression problem. Use a vector form of the equation.  \n",
    "\n",
    "\n",
    "> $ \\theta = \\left(X^{\\boldsymbol{\\top}}*X\\right)^{-1} * X^{\\boldsymbol{\\top}} * y $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cf1499",
   "metadata": {},
   "source": [
    "2. What changes in the solution when L1 and L2 regularizations are added to the loss function.  \n",
    "`Применяется система штрафов к весам, но с критическим различием:`  \n",
    " ` * L1-регуляризация (Lasso) добавляет штраф в виде суммы абсолютных значений весов, что приводит к разреженным решениям с обнулением неважных признаков`  \n",
    " ` * L2-регуляризация (Ridge) использует сумму квадратов весов, что равномерно сжимает все веса к нулю, сохраняя все признаки в модели, но уменьшая их влияние`  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc984f1",
   "metadata": {},
   "source": [
    "3. Explain why L1 regularization is often used to select features. Why are there many weights equal to 0 after the model is fit?  \n",
    "\n",
    "`L1-регуляризация (Lasso) приводит к обнулению весов неважных признаков благодаря использованию штрафа в виде суммы абсолютных значений весов (λ·Σ|wᵢ|), что создает разреженное решение — поскольку функция потерь с L1-штрафом имеет острые углы в точках, где некоторые веса равны нулю, оптимизация часто сходится именно к этим точкам, автоматически исключая менее значимые признаки из модели.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfdfd28",
   "metadata": {},
   "source": [
    "4. Explain how you can use the same models (Linear regression, Ridge, etc.) but make it possible to fit nonlinear dependencies.  \n",
    "\n",
    ">Для учёта нелинейных зависимостей в Линейных моделях признаким подвергают обработке:  \n",
    ">  * используют полиномы\n",
    ">  * используют логарифмы\n",
    ">  * используют экспоненту\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd247f42",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2. Introduction — make all the preprocessing staff from the previous lesson  \n",
    "\n",
    "a. Import libraries.  \n",
    "b. Read Train and Test Parts.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44a4fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.a\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bf0ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.b\n",
    "\n",
    "df = pd.concat([\n",
    "    pd.read_json(\"./datasets/train.json\"),\n",
    "    pd.read_json(\"./datasets/test.json\")\n",
    "])\n",
    "\n",
    "uq = df[\"price\"].quantile(0.99)\n",
    "lq = df[\"price\"].quantile(0.01)\n",
    "df = df[(df[\"price\"] <= uq) & (df[\"price\"] >= lq)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05678f7",
   "metadata": {},
   "source": [
    "### 3. Intro data analysis part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6356317",
   "metadata": {},
   "source": [
    "a. Let's generate additional features for better model quality. Consider a column called \"Features\". It consists of a list of highlights of the current flat.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3976520f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     [Dining Room, Pre-War, Laundry in Building, Di...\n",
       "6     [Doorman, Elevator, Laundry in Building, Dishw...\n",
       "9     [Doorman, Elevator, Laundry in Building, Laund...\n",
       "10                                                   []\n",
       "15    [Doorman, Elevator, Fitness Center, Laundry in...\n",
       "Name: features, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.a\n",
    "\n",
    "df[\"features\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bb2877",
   "metadata": {},
   "source": [
    "b. Remove unused symbols ([,], ', \", and space) from the column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70c35a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.b\n",
    "\n",
    "pattern = re.compile(r\"[\\[\\]\\'\\\"\\s]\")\n",
    "remove_sym = (lambda x: list([re.sub(pattern, '', elem) for elem in x]))\n",
    "df[\"features\"] = df[\"features\"].apply(remove_sym)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6017fdd",
   "metadata": {},
   "source": [
    "c. Get all values in each list and collect the result in one huge list for the whole dataset. You can use DataFrame.iterrows().  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3f2c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.c\n",
    "\n",
    "tot_features = df[\"features\"].explode().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705d5801",
   "metadata": {},
   "source": [
    "d. How many unique values does a result list contain?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07e67010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10669"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.d\n",
    "\n",
    "len(set(tot_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796309e9",
   "metadata": {},
   "source": [
    "e. Let's get acquainted with the new library — Collections. With this package you could effectively get quantity statistics about your data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e02bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.e\n",
    "\n",
    "cnt = collections.Counter(tot_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238dbe02",
   "metadata": {},
   "source": [
    "f. Count the most popular functions from our huge list and take the top 20 for this moment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0161e87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Elevator', 63653),\n",
       " ('CatsAllowed', 58204),\n",
       " ('HardwoodFloors', 58175),\n",
       " ('DogsAllowed', 54272),\n",
       " ('Doorman', 51332),\n",
       " ('Dishwasher', 50260),\n",
       " ('NoFee', 44759),\n",
       " ('LaundryinBuilding', 40306),\n",
       " ('FitnessCenter', 32780),\n",
       " ('Pre-War', 22695),\n",
       " ('LaundryinUnit', 21172),\n",
       " ('RoofDeck', 16164),\n",
       " ('OutdoorSpace', 13080),\n",
       " ('DiningRoom', 12231),\n",
       " ('HighSpeedInternet', 10424),\n",
       " ('Balcony', 7415),\n",
       " ('SwimmingPool', 6922),\n",
       " ('LaundryInBuilding', 6437),\n",
       " ('NewConstruction', 6229),\n",
       " ('Terrace', 5387)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.f\n",
    "\n",
    "cnt.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd544305",
   "metadata": {},
   "source": [
    "g. If everything is correct, you should get next values: 'Elevator', 'CatsAllowed', 'HardwoodFloors', 'DogsAllowed', 'Doorman', 'Dishwasher', 'NoFee', 'LaundryinBuilding', 'FitnessCenter', 'Pre-War', 'LaundryinUnit', 'RoofDeck', 'OutdoorSpace', 'DiningRoom', 'HighSpeedInternet', 'Balcony', 'SwimmingPool', 'LaundryInBuilding', 'NewConstruction', 'Terrace'.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "018dd7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elevator',\n",
       " 'CatsAllowed',\n",
       " 'HardwoodFloors',\n",
       " 'DogsAllowed',\n",
       " 'Doorman',\n",
       " 'Dishwasher',\n",
       " 'NoFee',\n",
       " 'LaundryinBuilding',\n",
       " 'FitnessCenter',\n",
       " 'Pre-War',\n",
       " 'LaundryinUnit',\n",
       " 'RoofDeck',\n",
       " 'OutdoorSpace',\n",
       " 'DiningRoom',\n",
       " 'HighSpeedInternet',\n",
       " 'Balcony',\n",
       " 'SwimmingPool',\n",
       " 'LaundryInBuilding',\n",
       " 'NewConstruction',\n",
       " 'Terrace']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.g\n",
    "\n",
    "most_common = list(dict(cnt.most_common(20)).keys())\n",
    "most_common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686ad1af",
   "metadata": {},
   "source": [
    "h. Now create 20 new features based on the top 20 values: 1 if the value is in the \"Feature\" column, otherwise 0.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11ee0930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.h\n",
    "\n",
    "for feature in most_common:\n",
    "    df[feature] = (\n",
    "        df[\"features\"]\n",
    "        .apply(lambda x: 1 if feature in x else 0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0051d410",
   "metadata": {},
   "source": [
    "i. Extend our feature set with 'bathrooms', 'bedrooms' and create a special variable feature_list with all feature names. Now we have 22 values. All models should be trained on these 22 features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a1fe3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(91182, 35)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(30395, 35)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3.i\n",
    "\n",
    "target = [\"price\"]\n",
    "rooms = [\"bathrooms\", \"bedrooms\"]\n",
    "most_common.extend(rooms)\n",
    "\n",
    "train_df, test_df = train_test_split(df, random_state=21)\n",
    "\n",
    "display(\n",
    "    len(most_common),\n",
    "    train_df.shape,\n",
    "    test_df.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e1edb7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 4. Models implementation — Linear regression\n",
    "\n",
    "a. Implement a Python class for a linear regression algorithm with two basic methods — fit and predict. Use stochastic gradient descent (SGD) to find optimal model weights. For better understanding, we recommend implementing separate versions of the algorithm with the analytical solution and non-stochastic gradient descent under the hood.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44967021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.a\n",
    "\n",
    "class MyRegression:\n",
    "    def __init__(self, *, fit_intercept=True, tol=1e-04):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.tol = tol\n",
    "        self.converged = False\n",
    "\n",
    "        self.y_ndim = None\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.available_methods = {\n",
    "            \"sgd\": self._SGD,\n",
    "            \"bgd\": self._BGD,\n",
    "            \"analytical\": self._analytical,\n",
    "        }\n",
    "    \n",
    "    def _SGD(self, X, y):\n",
    "        \"Прототип стохастического градиентного спуска\"\n",
    "        pass\n",
    "\n",
    "    def _BGD(self, X, y):\n",
    "        \"Прототип нестохастического градиентного спуска\"\n",
    "        pass\n",
    "    \n",
    "    def _analytical(self, X, y):\n",
    "        \"Прототип аналитического решения(через систему уравнений)\"\n",
    "        pass\n",
    "\n",
    "    def _prepare_data(self, X, y):\n",
    "        \"\"\"\n",
    "        Функция преобразует данные в numpy массив для оптимизации\n",
    "        \"\"\"\n",
    "        # детерминирует SGD убирая случайность и добавляя воспроизводимость результатов\n",
    "        random = np.random.RandomState(42)\n",
    "        r, c = X.shape\n",
    "        if hasattr(X, \"values\"):\n",
    "            X = X.values\n",
    "        if self.fit_intercept:\n",
    "            X_bias = np.c_[np.ones((r, 1)), X]\n",
    "            weights = random.randn(c + 1)\n",
    "        else:\n",
    "            X_bias = X\n",
    "            weights = random.randn(c)\n",
    "\n",
    "        y_v = y.values.ravel()\n",
    "        return X_bias, weights, y_v, random\n",
    "\n",
    "    def _check_convergence(self, weights, prev_weights):\n",
    "        \"\"\"\n",
    "        Функция проверяет 'схождение градиента'\n",
    "        и возращает да/нет - сошелся/не сошелся\n",
    "        \"\"\"\n",
    "        if self.tol is not None:\n",
    "            weight_change = np.linalg.norm(weights - prev_weights)\n",
    "            if weight_change < self.tol:\n",
    "                self.converged = True\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _extract_results(self, weights):\n",
    "        \"\"\"\n",
    "        Функция проверяет условие 'свободный член' и возращает веса\n",
    "        c bias или без него\n",
    "        \"\"\"\n",
    "        if self.fit_intercept:\n",
    "            return weights[0], weights[1:]\n",
    "        else:\n",
    "            return 0.0, weights\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        use_method = self.available_methods.get(self.method)\n",
    "        self.y_shape = y.shape\n",
    "\n",
    "        if use_method:\n",
    "            self.intercept_, self.coef_ = use_method(X, y)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Unknown method: '{self.method}'. \" +\n",
    "                f\"Available: {list(self.available_methods.keys())}\"\n",
    "            )\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array(X.values.dot(self.coef_) + self.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce036d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.a\n",
    "\n",
    "class MyLinearRegression(MyRegression):\n",
    "    def __init__(self,\n",
    "                 method=\"sgd\",\n",
    "                 *,\n",
    "                 gamma=0.001,\n",
    "                 epochs=100_000,\n",
    "                 fit_intercept=True,\n",
    "                 tol=1e-04):\n",
    "        super().__init__(fit_intercept=fit_intercept, tol=tol)\n",
    "        self.method = method\n",
    "        self.gamma = gamma\n",
    "        self.epochs = epochs\n",
    "    \n",
    "    def _SGD(self, X, y):\n",
    "        \"Функция вычисления стохастического градинтного спуска\"\n",
    "        X_bias, weights, y_v, random = self._prepare_data(X, y)\n",
    "        prev_weights = weights.copy()\n",
    "        for _ in range(self.epochs):\n",
    "            idx = random.randint(0, X_bias.shape[0])\n",
    "            X_i = X_bias[idx]\n",
    "            y_i = y_v[idx]\n",
    "            predict = X_i.dot(weights)\n",
    "            error = predict - y_i\n",
    "            gradient = 2 * error * X_i\n",
    "            weights -= self.gamma * gradient\n",
    "\n",
    "            if self._check_convergence(weights, prev_weights):\n",
    "                break\n",
    "            prev_weights = weights.copy()\n",
    "        return self._extract_results(weights)\n",
    "\n",
    "    def _BGD(self, X, y):\n",
    "        \"\"\"\n",
    "        Функция вычисления нестохастического градиентного спуска\n",
    "        \"\"\"\n",
    "        X_bias, weights, y_v, _ = self._prepare_data(X, y)\n",
    "        prev_weights = weights.copy()\n",
    "        for _ in range(self.epochs):\n",
    "            predict = X_bias.dot(weights)\n",
    "            error = predict - y_v\n",
    "            gradient = 2 * X_bias.T.dot(error) / X_bias.shape[0]\n",
    "            weights -= self.gamma * gradient\n",
    "\n",
    "            if self._check_convergence(weights, prev_weights):\n",
    "                break\n",
    "            prev_weights = weights.copy()\n",
    "        return self._extract_results(weights)\n",
    "\n",
    "    def _analytical(self, X, y):\n",
    "        \"\"\"\n",
    "        Функция вычисляет градиентный спуск аналитическим методом\n",
    "        (через систему линейных уравнений)\n",
    "        \"\"\"\n",
    "        X_bias, _, y_v, _ = self._prepare_data(X, y)\n",
    "        XTX = X_bias.T.dot(X_bias)\n",
    "        XTy = X_bias.T.dot(y_v)\n",
    "        weights = np.linalg.solve(XTX, XTy)\n",
    "        return self._extract_results(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3fd469",
   "metadata": {},
   "source": [
    "b. What is determenistic model? Make SGD determenistic.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0a4fd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Детерминированная модель - это модель,\n",
      "    результаты которой можно воспроизвести.\n",
      "    Я реализовал это через строку 21 в классе,\n",
      "    добавив и заюзав переменную 'random = np.random.RandomState(42)'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4.b\n",
    "\n",
    "print(\"\"\"\n",
    "    Детерминированная модель - это модель,\n",
    "    результаты которой можно воспроизвести.\n",
    "    Я реализовал это через строку 21 в классе,\n",
    "    добавив и заюзав переменную 'random = np.random.RandomState(42)'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ffbbc4",
   "metadata": {},
   "source": [
    "c. Define the R squared (R2) coefficient and implement a function to calculate it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e140e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.c\n",
    "\n",
    "def dim(array):\n",
    "    \"Преобразуем размерности\"\n",
    "    return np.array(array).ravel()\n",
    "\n",
    "def TSS(y_true):\n",
    "    \"\"\"\n",
    "    TSS (Total Sum of Squares / Общая сумма квадратов)\n",
    "    Мера общей вариативности данных.\n",
    "    Сумма квадратов отклонений реальных значений от их среднего.\n",
    "\n",
    "    Формула: TSS = Σ(yᵢ - ȳ)²\n",
    "             где yᵢ — реальные значения, ȳ — их среднее.\n",
    "    \"\"\"\n",
    "    y_true = dim(y_true)\n",
    "    return np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "\n",
    "def RSS(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    RSS (Residual Sum of Squares / Сумма квадратов остатков)\n",
    "    Мера ошибки модели.\n",
    "    Сумма квадратов разниц между реальными значениями и предсказанными.\n",
    "\n",
    "    Формула: RSS = Σ(yᵢ - ŷᵢ)²\n",
    "             где yᵢ — реальные значения, ŷᵢ — предсказанные значения.\n",
    "    \"\"\"\n",
    "    y_true, y_pred = dim(y_true), dim(y_pred)\n",
    "    return np.sum((y_true - y_pred) ** 2)\n",
    "\n",
    "def r2_my(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    R² (коэффициент детерминации / r2_score)\n",
    "    Мера качества модели. Доля дисперсии зависимой переменной,\n",
    "    объяснённая моделью. Применяется в регрессионых моделях.\n",
    "\n",
    "    Формула: R² = 1 - RSS/TSS\n",
    "             где RSS — сумма квадратов остатков,\n",
    "                 TSS — общая сумма квадратов.\n",
    "\n",
    "    Интерпретация: R² ∈ (-∞, 1]\n",
    "                   где: 1 — идеальное предсказание\n",
    "                            (модель объясняет 100% дисперсии)\n",
    "                        0 — модель не лучше, чем предсказание средним\n",
    "                      < 0 — модель хуже, чем предсказание средним\n",
    "    в sklearn r2_score\n",
    "    \"\"\"\n",
    "    tss = TSS(y_true=y_true)\n",
    "    if tss:\n",
    "        return float(1 - (RSS(y_true=y_true, y_pred=y_pred) / tss))\n",
    "    else:\n",
    "        raise np.nan\n",
    "\n",
    "def MAE(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    MAE (Mean Absolute Error / Средняя абсолютная ошибка)\n",
    "    Среднее абсолютных разностей между предсказанными и реальными значениями.\n",
    "\n",
    "    Формула: MAE = (1/n) * Σ|yᵢ - ŷᵢ|\n",
    "             где yᵢ — реальные значения\n",
    "                 ŷᵢ — предсказанные\n",
    "                 n — количество наблюдений\n",
    "    Свойства:\n",
    "             Измеряется в тех же единицах, что и y\n",
    "             Менее чувствительна к выбросам, чем RMSE\n",
    "             Диапазон: [0, +∞), где 0 — идеальное предсказание\n",
    "    \"\"\"\n",
    "    y_true, y_pred = dim(y_true), dim(y_pred)\n",
    "    return float(np.mean(np.abs(y_true - y_pred)))\n",
    "\n",
    "def MSE(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    MSE (Mean Squared Error / Средняя квадратичная ошибка)\n",
    "    Среднее значение квадратов разностей между предсказанными и реальными значениями.\n",
    "\n",
    "    Формула: MSE = (1/n) * Σ(yᵢ - ŷᵢ)²\n",
    "             где yᵢ — реальные значения\n",
    "                 ŷᵢ — предсказанные\n",
    "                 n — количество наблюдений.\n",
    "    \"\"\"\n",
    "    y_true, y_pred = dim(y_true), dim(y_pred)\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def RMSE(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    RMSE (Root Mean Square Error / Среднеквадратичная ошибка)\n",
    "    Корень из среднего квадратов разностей между предсказанными\n",
    "    и реальными значениями.\n",
    "\n",
    "    Формула: RMSE = √[(1/n) * Σ(yᵢ - ŷᵢ)²]\n",
    "             где yᵢ — реальные значения\n",
    "                 ŷᵢ — предсказанные\n",
    "                 n — количество наблюдений\n",
    "    Свойства:\n",
    "             Измеряется в тех же единицах, что и y\n",
    "             Более чувствительна к выбросам, чем MAE\n",
    "             Усиливает большие ошибки (из-за квадрата)\n",
    "    Диапазон: [0, +∞), где 0 — идеальное предсказание\n",
    "    \"\"\"\n",
    "    return float(np.sqrt(MSE(y_true=y_true, y_pred=y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7034b8d",
   "metadata": {},
   "source": [
    "d. Make predictions with your algorithm and estimate the model with MAE, RMSE and R2 metrics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68112206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.d\n",
    "\n",
    "metrics = dict()\n",
    "\n",
    "def show_metrics(model, X_train, X_test, features, y, *, show=False):\n",
    "    class_name = model.__class__.__name__\n",
    "\n",
    "    model.fit(X_train[features], X_train[y])\n",
    "\n",
    "    y_train_pred = model.predict(X_train[features])\n",
    "    y_test_pred = model.predict(X_test[features])\n",
    "\n",
    "    mae_train = MAE(X_train[y], y_train_pred)\n",
    "    mae_test = MAE(X_test[y], y_test_pred)\n",
    "\n",
    "    rmse_train = RMSE(X_train[y], y_train_pred)\n",
    "    rmse_test = RMSE(X_test[y], y_test_pred)\n",
    "\n",
    "    r2_train = r2_my(X_train[y], y_train_pred)\n",
    "    r2_test = r2_my(X_test[y], y_test_pred)\n",
    "\n",
    "    if show:\n",
    "        print(\n",
    "            f\"'{class_name}' train MAE:  {mae_train:>2.6f}\",\n",
    "            f\"'{class_name}' train RMSE: {rmse_train:>2.6f}\",\n",
    "            f\"'{class_name}' train R2:   {r2_train:>2.6f}\",\n",
    "            sep=\"\\n\",\n",
    "            end=\"\\n\" * 2\n",
    "        )\n",
    "        print(\n",
    "            f\"'{class_name}' test MAE:  {mae_test:>2.6f}\",\n",
    "            f\"'{class_name}' test RMSE: {rmse_test:>2.6f}\",\n",
    "            f\"'{class_name}' test R2:   {r2_test:>2.6f}\",\n",
    "            sep=\"\\n\",\n",
    "            end=\"\\n\" * 2\n",
    "        )\n",
    "    return {\n",
    "        \"train\": {\"mae\": mae_train, \"rmse\": rmse_train, \"r2_score\": r2_train},\n",
    "        \"test\": {\"mae\": mae_test, \"rmse\": rmse_test, \"r2_score\": r2_test},\n",
    "    }\n",
    "\n",
    "\n",
    "metrics[\"MyLinearRegression\"] = show_metrics(\n",
    "    MyLinearRegression(\"sgd\"),\n",
    "    train_df,\n",
    "    test_df,\n",
    "    most_common,\n",
    "    target\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5dc1c8",
   "metadata": {},
   "source": [
    "e. Initialize LinearRegression() from sklearn.linear_model, fit the model, and predict the training and test parts as in the previous lesson.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8a9efdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.e\n",
    "\n",
    "metrics[\"LinearRegression\"] = show_metrics(\n",
    "    LinearRegression(),\n",
    "    train_df,\n",
    "    test_df,\n",
    "    most_common,\n",
    "    target,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf28d449",
   "metadata": {},
   "source": [
    "f. Compare the quality metrics and make sure the difference is small (between your implementations and sklearn).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bed7fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deviation test MAE  [my/default]: -2.59%\n",
      "Deviation test RMSE [my/default]: +2.05%\n",
      "Deviation test R²   [my/default]: -3.37%\n"
     ]
    }
   ],
   "source": [
    "# 4.f\n",
    "\n",
    "mae = (100 - metrics['MyLinearRegression']['test']['mae'] / \n",
    "       metrics['LinearRegression']['test']['mae'] * 100)\n",
    "rmse = (100 - metrics['MyLinearRegression']['test']['rmse'] / \n",
    "        metrics['LinearRegression']['test']['rmse'] * 100)\n",
    "r2 = (100 - metrics['MyLinearRegression']['test']['r2_score'] / \n",
    "            metrics['LinearRegression']['test']['r2_score'] * 100)\n",
    "print(\n",
    "    f\"Deviation test MAE  [my/default]: {mae:>+2.2f}%\",\n",
    "    f\"Deviation test RMSE [my/default]: {rmse:>+2.2f}%\",\n",
    "    f\"Deviation test R²   [my/default]: {r2:>+2.2f}%\",\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4595ca8",
   "metadata": {},
   "source": [
    "g. Store the metrics as in the previous lesson in a table with columns model, train, test for MAE table, RMSE table, and R2 coefficient.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb74617e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <th>MyLinearRegression</th>\n",
       "      <td>760.580005</td>\n",
       "      <td>755.121589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                         train        test\n",
       "metric model                                     \n",
       "mae    MyLinearRegression  760.580005  755.121589"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <th>MyLinearRegression</th>\n",
       "      <td>1212.694679</td>\n",
       "      <td>1048.465824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                          train         test\n",
       "metric model                                       \n",
       "rmse   MyLinearRegression  1212.694679  1048.465824"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2_score</th>\n",
       "      <th>MyLinearRegression</th>\n",
       "      <td>0.421523</td>\n",
       "      <td>0.564469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                         train      test\n",
       "metric   model                                 \n",
       "r2_score MyLinearRegression  0.421523  0.564469"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4.g\n",
    "\n",
    "def get_scores_df(metrics: dict):\n",
    "    temp = []\n",
    "    for key, scores in metrics.items():\n",
    "        for dataset, values in scores.items():\n",
    "            for metric, value in values.items():\n",
    "                temp.append({\"model\": key,\n",
    "                             \"dataset\": dataset,\n",
    "                             \"metric\": metric,\n",
    "                             \"value\": value,})\n",
    "    temp = pd.DataFrame(temp).pivot_table(index=['metric', 'model'],\n",
    "                                          columns='dataset',\n",
    "                                          values='value')\n",
    "    return temp[[\"train\", \"test\"]].round(7)\n",
    "\n",
    "\n",
    "metrics_df4 = get_scores_df(metrics)\n",
    "mask = metrics_df4.index.get_level_values('model').str.startswith('My')\n",
    "display(\n",
    "    metrics_df4[mask].loc[[\"mae\"]].sort_values(by=\"test\", ascending=True),\n",
    "    metrics_df4[mask].loc[[\"rmse\"]].sort_values(by=\"test\", ascending=True),\n",
    "    metrics_df4[mask].loc[[\"r2_score\"]].sort_values(by=\"test\", ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c4a0c7",
   "metadata": {},
   "source": [
    "### 5. Regularized models implementation — Ridge, Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772a72e0",
   "metadata": {},
   "source": [
    "##### a. Implement Ridge, Lasso, ElasticNet algorithms: extend the loss function with L2, L1 and both regularizations accordingly.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6226d955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.a\n",
    "\n",
    "class MyRegularization(MyRegression):\n",
    "    def __init__(self, *, alpha=1.0, l1_ratio=0.5, penalty=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.penalty = penalty\n",
    "        self.penalties = {\n",
    "            \"l2\": lambda w: 2 * self.alpha * w,\n",
    "            \"l1\": lambda w: self.alpha * np.sign(w),\n",
    "            \"l1+l2\": lambda w: (\n",
    "                self.alpha * self.l1_ratio * np.sign(w) + \n",
    "                2 * self.alpha * (1 - self.l1_ratio) * w\n",
    "            )\n",
    "        }\n",
    "\n",
    "    def _SGD(self, X, y, gamma=0.001, epochs=10_000):\n",
    "        X_bias, weights, y_v, random = self._prepare_data(X, y)\n",
    "        for _ in range(epochs):\n",
    "            idx = random.randint(0, X_bias.shape[0])\n",
    "            X_i = X_bias[idx]\n",
    "            y_i = y_v[idx]\n",
    "            predict = X_i.dot(weights)\n",
    "            error = predict - y_i\n",
    "            gradient = 2 * error * X_i\n",
    "            reg_f = self.penalties[self.penalty](weights)\n",
    "            if self.fit_intercept:\n",
    "                reg_f[0] = 0\n",
    "            gradient += reg_f\n",
    "            weights -= gamma * gradient\n",
    "        return self._extract_results(weights)\n",
    "\n",
    "    def _BGD(self, X, y, gamma=0.0001, epochs=10_000):\n",
    "        X_bias, weights, y_v, _ = self._prepare_data(X, y)\n",
    "        for _ in range(epochs):\n",
    "            predict = X_bias.dot(weights)\n",
    "            error = predict - y_v\n",
    "            gradient = 2 * X_bias.T.dot(error) / X_bias.shape[0]\n",
    "            reg_f = self.penalties[self.penalty](weights)\n",
    "            if self.fit_intercept:\n",
    "                reg_f[0] = 0\n",
    "            gradient += reg_f\n",
    "            weights -= gamma * gradient\n",
    "\n",
    "        return self._extract_results(weights)\n",
    "\n",
    "    def _analytical(self, X, y):\n",
    "        X_bias, _, y_v, _ = self._prepare_data(X, y)\n",
    "        I = np.eye(X_bias.shape[1])\n",
    "        if self.fit_intercept:\n",
    "            I[0, 0] = 0\n",
    "        \n",
    "        XTX = X_bias.T.dot(X_bias)\n",
    "        XTX_l = XTX + self.alpha * I\n",
    "        XTy = X_bias.T.dot(y_v)\n",
    "        weights = np.linalg.solve(XTX_l, XTy)\n",
    "\n",
    "        return self._extract_results(weights)\n",
    "\n",
    "class MyRidge(MyRegularization):\n",
    "    def __init__(self, method=\"analytical\", *, alpha=1, l1_ratio=0.5, penalty=\"l2\", **kwargs):\n",
    "        super().__init__(alpha=alpha, l1_ratio=l1_ratio, penalty=penalty, **kwargs)\n",
    "        self.method = method\n",
    "\n",
    "class MyLasso(MyRegularization):\n",
    "    def __init__(self, method=\"sgd\", *, alpha=1, l1_ratio=0.5, penalty=\"l1\", **kwargs):\n",
    "        super().__init__(alpha=alpha, l1_ratio=l1_ratio, penalty=penalty, **kwargs)\n",
    "        self.method = method\n",
    "\n",
    "    def _analytical(self, X, y):\n",
    "        raise NotImplementedError(\"Lasso has no closed-form solution\")\n",
    "\n",
    "class MyElasticNet(MyRegularization):\n",
    "    def __init__(self, method=\"sgd\", *, alpha=1, l1_ratio=0.5, **kwargs):\n",
    "        super().__init__(alpha=alpha, l1_ratio=l1_ratio, penalty=\"l1+l2\", **kwargs)\n",
    "        self.method = method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee49eea",
   "metadata": {},
   "source": [
    "b. Make predictions with your algorithm and estimate the model with MAE, RMSE and R2 metrics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04f70d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.b\n",
    "\n",
    "metrics[\"MyRidge\"] = show_metrics(\n",
    "    MyRidge(),\n",
    "    train_df,\n",
    "    test_df,\n",
    "    most_common,\n",
    "    target\n",
    ")\n",
    "metrics[\"MyLasso\"] = show_metrics(\n",
    "     MyLasso(),\n",
    "     train_df,\n",
    "     test_df,\n",
    "     most_common,\n",
    "     target\n",
    ")\n",
    "metrics[\"MyElasticNet\"] = show_metrics(\n",
    "     MyElasticNet(),\n",
    "     train_df,\n",
    "     test_df,\n",
    "     most_common,\n",
    "     target\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39597252",
   "metadata": {},
   "source": [
    "c. Initialize Ridge(), Lasso(), and ElasticNet() from sklearn.linear_model, fit the model, and make predictions for the training and test samples as in the previous lesson.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6e80f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.c\n",
    "\n",
    "metrics[\"Ridge\"] = show_metrics(\n",
    "     Ridge(random_state=21),\n",
    "     train_df,\n",
    "     test_df,\n",
    "     most_common,\n",
    "     target\n",
    ")\n",
    "metrics[\"Lasso\"] = show_metrics(\n",
    "     Lasso(random_state=21),\n",
    "     train_df,\n",
    "     test_df,\n",
    "     most_common,\n",
    "     target\n",
    ")\n",
    "metrics[\"ElasticNet\"] = show_metrics(\n",
    "     ElasticNet(random_state=21),\n",
    "     train_df,\n",
    "     test_df,\n",
    "     most_common,\n",
    "     target\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2cee7e",
   "metadata": {},
   "source": [
    "d. Compare quality metrics and make sure the difference is small (between your implementations and sklearn).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "056b6bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge: deviation test MAE  [my/default]: -0.00%\n",
      "Ridge: deviation test RMSE [my/default]: -0.00%\n",
      "Ridge: deviation test R²   [my/default]: +0.00%\n",
      "\n",
      "Lasso: deviation test MAE  [my/default]: +4.30%\n",
      "Lasso: deviation test RMSE [my/default]: +3.89%\n",
      "Lasso: deviation test R²   [my/default]: -6.35%\n",
      "\n",
      "ElasticNet: deviation test MAE  [my/default]: +1.92%\n",
      "ElasticNet: deviation test RMSE [my/default]: -0.01%\n",
      "ElasticNet: deviation test R²   [my/default]: +0.02%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5.d\n",
    "\n",
    "mae = (100 - metrics['MyRidge']['test']['mae'] / \n",
    "       metrics['Ridge']['test']['mae'] * 100)\n",
    "rmse = (100 - metrics['MyRidge']['test']['rmse'] / \n",
    "        metrics['Ridge']['test']['rmse'] * 100)\n",
    "r2 = (100 - metrics['MyRidge']['test']['r2_score'] / \n",
    "            metrics['Ridge']['test']['r2_score'] * 100)\n",
    "print(\n",
    "    f\"Ridge: deviation test MAE  [my/default]: {mae:>+2.2f}%\",\n",
    "    f\"Ridge: deviation test RMSE [my/default]: {rmse:>+2.2f}%\",\n",
    "    f\"Ridge: deviation test R²   [my/default]: {r2:>+2.2f}%\",\n",
    "    sep=\"\\n\", end=\"\\n\" * 2\n",
    ")\n",
    "\n",
    "# > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > \n",
    "mae = (100 - metrics['MyLasso']['test']['mae'] / \n",
    "       metrics['Lasso']['test']['mae'] * 100)\n",
    "rmse = (100 - metrics['MyLasso']['test']['rmse'] / \n",
    "        metrics['Lasso']['test']['rmse'] * 100)\n",
    "r2 = (100 - metrics['MyLasso']['test']['r2_score'] / \n",
    "            metrics['Lasso']['test']['r2_score'] * 100)\n",
    "print(\n",
    "    f\"Lasso: deviation test MAE  [my/default]: {mae:>+2.2f}%\",\n",
    "    f\"Lasso: deviation test RMSE [my/default]: {rmse:>+2.2f}%\",\n",
    "    f\"Lasso: deviation test R²   [my/default]: {r2:>+2.2f}%\",\n",
    "    sep=\"\\n\", end=\"\\n\" * 2\n",
    ")\n",
    "\n",
    "# > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > \n",
    "mae = (100 - metrics['MyElasticNet']['test']['mae'] / \n",
    "       metrics['ElasticNet']['test']['mae'] * 100)\n",
    "rmse = (100 - metrics['MyElasticNet']['test']['rmse'] / \n",
    "        metrics['ElasticNet']['test']['rmse'] * 100)\n",
    "r2 = (100 - metrics['MyElasticNet']['test']['r2_score'] / \n",
    "            metrics['ElasticNet']['test']['r2_score'] * 100)\n",
    "print(\n",
    "    f\"ElasticNet: deviation test MAE  [my/default]: {mae:>+2.2f}%\",\n",
    "    f\"ElasticNet: deviation test RMSE [my/default]: {rmse:>+2.2f}%\",\n",
    "    f\"ElasticNet: deviation test R²   [my/default]: {r2:>+2.2f}%\",\n",
    "    sep=\"\\n\", end=\"\\n\" * 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ea7e13",
   "metadata": {},
   "source": [
    "e. Store the metrics as in the previous lesson in a table with columns model, train, test for MAE table, RMSE table, and R2 coefficient.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b9c3d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">mae</th>\n",
       "      <th>MyLasso</th>\n",
       "      <td>710.935537</td>\n",
       "      <td>704.009476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>741.231856</td>\n",
       "      <td>735.663774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge</th>\n",
       "      <td>741.794252</td>\n",
       "      <td>736.033898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>741.794252</td>\n",
       "      <td>736.033898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>741.796757</td>\n",
       "      <td>736.035889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression</th>\n",
       "      <td>760.580005</td>\n",
       "      <td>755.121589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet</th>\n",
       "      <td>802.731810</td>\n",
       "      <td>797.985764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>817.741302</td>\n",
       "      <td>813.592687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                         train        test\n",
       "metric model                                     \n",
       "mae    MyLasso             710.935537  704.009476\n",
       "       Lasso               741.231856  735.663774\n",
       "       MyRidge             741.794252  736.033898\n",
       "       Ridge               741.794252  736.033898\n",
       "       LinearRegression    741.796757  736.035889\n",
       "       MyLinearRegression  760.580005  755.121589\n",
       "       MyElasticNet        802.731810  797.985764\n",
       "       ElasticNet          817.741302  813.592687"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">rmse</th>\n",
       "      <th>MyLasso</th>\n",
       "      <td>1190.402330</td>\n",
       "      <td>1029.196327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression</th>\n",
       "      <td>1212.694679</td>\n",
       "      <td>1048.465824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>1118.153173</td>\n",
       "      <td>1070.385068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge</th>\n",
       "      <td>1118.153174</td>\n",
       "      <td>1070.386872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>1118.153174</td>\n",
       "      <td>1070.386872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>1118.300061</td>\n",
       "      <td>1070.842714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>1213.614587</td>\n",
       "      <td>1197.641981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet</th>\n",
       "      <td>1217.781706</td>\n",
       "      <td>1197.739219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                          train         test\n",
       "metric model                                       \n",
       "rmse   MyLasso             1190.402330  1029.196327\n",
       "       MyLinearRegression  1212.694679  1048.465824\n",
       "       LinearRegression    1118.153173  1070.385068\n",
       "       MyRidge             1118.153174  1070.386872\n",
       "       Ridge               1118.153174  1070.386872\n",
       "       Lasso               1118.300061  1070.842714\n",
       "       ElasticNet          1213.614587  1197.641981\n",
       "       MyElasticNet        1217.781706  1197.739219"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">r2_score</th>\n",
       "      <th>MyLasso</th>\n",
       "      <td>0.442595</td>\n",
       "      <td>0.580331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression</th>\n",
       "      <td>0.421523</td>\n",
       "      <td>0.564469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.508203</td>\n",
       "      <td>0.546068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge</th>\n",
       "      <td>0.508203</td>\n",
       "      <td>0.546066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.508203</td>\n",
       "      <td>0.546066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.508074</td>\n",
       "      <td>0.545680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>0.420645</td>\n",
       "      <td>0.431717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet</th>\n",
       "      <td>0.416660</td>\n",
       "      <td>0.431624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                         train      test\n",
       "metric   model                                 \n",
       "r2_score MyLasso             0.442595  0.580331\n",
       "         MyLinearRegression  0.421523  0.564469\n",
       "         LinearRegression    0.508203  0.546068\n",
       "         MyRidge             0.508203  0.546066\n",
       "         Ridge               0.508203  0.546066\n",
       "         Lasso               0.508074  0.545680\n",
       "         ElasticNet          0.420645  0.431717\n",
       "         MyElasticNet        0.416660  0.431624"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5.e\n",
    "\n",
    "metrics_df5 = get_scores_df(metrics)\n",
    "# mask = metrics_df5.index.get_level_values('model').str.startswith('My')\n",
    "display(\n",
    "    metrics_df5.loc[[\"mae\"]].sort_values(by=\"test\", ascending=True),\n",
    "    metrics_df5.loc[[\"rmse\"]].sort_values(by=\"test\", ascending=True),\n",
    "    metrics_df5.loc[[\"r2_score\"]].sort_values(by=\"test\", ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc027c45",
   "metadata": {},
   "source": [
    "### 6. Feature normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118f8f70",
   "metadata": {},
   "source": [
    "a. First, write several examples of why and where feature normalization is mandatory and vice versa.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20316cc1",
   "metadata": {},
   "source": [
    ">\\# 6.a\n",
    "\n",
    "**Нормализация обязательная**:\n",
    "1. Метрические алгоритмы (основанные на расстояниях):\n",
    "K-ближайших соседей (KNN) — если один признак измеряется в километрах (0–1000), а другой в сантиметрах (0–100), расстояние будет доминироваться первым признаком.  \n",
    "K-средних (K-means) — та же проблема, кластеры будут формироваться по признакам с наибольшим разбросом.  \n",
    "Метод опорных векторов (SVM) с RBF-ядром — использует расстояния между точками.  \n",
    "\n",
    "2. Градиентные методы оптимизации:\n",
    "Линейная/логистическая регрессия с градиентным спуском — разный масштаб признаков приводит к \"оврагоподобной\" поверхности ошибок, что замедляет сходимость.  \n",
    "Нейронные сети — градиенты по весам для признаков разного масштаба будут сильно отличаться, требуя адаптивных методов оптимизации (Adam) или нормализации.  \n",
    "\n",
    "3. Методы с регуляризацией:  \n",
    "Ridge/Lasso/ElasticNet — регуляризация штрафует большие веса. Признаки с большим масштабом будут искусственно занижены, а с малым — завышены.  \n",
    "\n",
    "4. Методы, основанные на ковариации/корреляции:  \n",
    "PCA (метод главных компонент) — ищет направления максимальной дисперсии. Признаки с большим разбросом будут доминировать без нормализации.  \n",
    "LDA (линейный дискриминантный анализ) — предполагает равноценность признаков.  \n",
    "\n",
    "**Нормализация НЕ ТРЕБУЕТСЯ или ВРЕДНА**:  \n",
    "1. Деревья решений и их ансамбли:  \n",
    "Random Forest, XGBoost, LightGBM — разделение происходит по пороговым значениям, масштаб не важен. Нормализация только замедлит вычисления.  \n",
    "\n",
    "2. Наивный Байес:  \n",
    "Работает с вероятностями, независимыми от масштаба.  \n",
    "\n",
    "3. Методы, основанные на рангах:  \n",
    "Деревья решений (опять же) — используют порядок значений, а не абсолютные величины.  \n",
    "\n",
    "4. Когда признаки уже в сопоставимых единицах:  \n",
    "Все признаки измерены в одной единице (например, проценты от 0 до 100).  \n",
    "\n",
    "5. Когда важна интерпретируемость:  \n",
    "В линейной регрессии без регуляризации через Метод Наименьших Квадратов — коэффициенты сохраняют естественную интерпретацию (изменение y при изменении x на 1 единицу измерения).  \n",
    "\n",
    "6. Когда данные уже нормализованы по природе:  \n",
    "Пиксели изображений (0–255) или текст после TF-IDF (относительные частоты).  \n",
    "\n",
    "Важное замечание:  \n",
    "Нормализация меняет масштаб, что может скрыть важные особенности данных (например, выбросы становятся менее заметными). Нормализация работает только с числовыми признаками."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeda339",
   "metadata": {},
   "source": [
    "b. Let's consider the first of the classical normalization methods — MinMaxScaler. Write a mathematical formula for this method.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7886c2",
   "metadata": {},
   "source": [
    ">\\# 6.b\n",
    "\n",
    "$ MinMaxScaler = \\LARGE \\frac{x_i - \\min{(x)}}{\\max{(x)} - \\min{(x)}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d026dfc",
   "metadata": {},
   "source": [
    "c. Implement your own function or class for MinMaxScaler feature normalization.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "467081c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.c\n",
    "\n",
    "class MyMinMaxScaler:\n",
    "    def __init__(self):\n",
    "        self.features_name_in_ = None\n",
    "        self.min_ = None\n",
    "        self.mm_range_ = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        if not all(pd.api.types.is_numeric_dtype(X[col]) \n",
    "                  for col in X.columns):\n",
    "            raise ValueError(\"Колонки должны иметь числовой тип!!!\")\n",
    "\n",
    "        self.features_name_in_ = X.columns.tolist()\n",
    "        X_f = X.values\n",
    "        max_ = X_f.max(axis=0)\n",
    "        self.min_ = X_f.min(axis=0)\n",
    "        self.mm_range_ = max_ - self.min_\n",
    "        self.mm_range_[self.mm_range_ == 0] = 1.\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_float = X.values\n",
    "        X_scaled = (X_float - self.min_) / self.mm_range_\n",
    "        return X_scaled.round(18)\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        return np.array(self.fit(X).transform(X))\n",
    "\n",
    "\n",
    "myminmax = MyMinMaxScaler()\n",
    "myminmax.fit(train_df[rooms])\n",
    "test_myminmax = myminmax.transform(test_df[rooms])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7350f730",
   "metadata": {},
   "source": [
    "d. Initialize MinMaxScaler() from sklearn.preprocessing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d507385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.d\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "minmax.fit(train_df[rooms])\n",
    "test_minmax = minmax.transform(test_df[rooms])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2470edd7",
   "metadata": {},
   "source": [
    "e. Compare the feature normalization with your own method and with sklearn.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "715579e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нормализация различается\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67864    0.022321\n",
       "Name: bathrooms, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "67864    0.022321\n",
       "Name: bathrooms, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6.e\n",
    "\n",
    "if np.array_equal(test_myminmax, test_minmax):\n",
    "    print(\"Результат нормализации идентичен\")\n",
    "else:\n",
    "    print(\"Нормализация различается\")\n",
    "\n",
    "temp_df1, temp_df2 = test_df.copy(), test_df.copy()\n",
    "temp_df1[rooms], temp_df2[rooms] = test_myminmax, test_minmax\n",
    "mask = temp_df1[\"bathrooms\"] == temp_df2[\"bathrooms\"]\n",
    "display(\n",
    "    temp_df1[~mask][\"bathrooms\"].head(1),\n",
    "    temp_df2[~mask][\"bathrooms\"].head(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8065020",
   "metadata": {},
   "source": [
    "f. Repeat the steps from b to e for another normalization method StandardScaler.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e0b5c0",
   "metadata": {},
   "source": [
    ">\\# 6.f\n",
    "\n",
    "$ StandartScaler = \\LARGE \\frac{x_i - \\text{mean}{(x)}}{\\text{stdev} (x)} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb02121d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат нормализации идентичен\n"
     ]
    }
   ],
   "source": [
    "# 6.f\n",
    "\n",
    "class MyStandardScaler:\n",
    "    def __init__(self):\n",
    "        self.features_name_in_ = None\n",
    "        self.mean_ = None\n",
    "        self.std_ = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        if not all(pd.api.types.is_numeric_dtype(X[col]) \n",
    "                  for col in X.columns):\n",
    "            raise ValueError(\"Колонки должны иметь числовой тип!!!\")\n",
    "\n",
    "        self.features_name_in_ = X.columns.tolist()\n",
    "        X_array = np.array(X)\n",
    "\n",
    "        self.mean_ = np.mean(X_array, axis=0)\n",
    "        self.std_ = np.std(X_array, axis=0)\n",
    "        self.std_[self.std_ == 0] = 1\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_array = np.array(X)\n",
    "        X_scaled = (X_array - self.mean_) / self.std_\n",
    "        return pd.DataFrame(X_scaled, columns=self.features_name_in_, index=X.index)\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        return np.array(self.fit(X).transform(X))\n",
    "\n",
    "\n",
    "myscaler = MyStandardScaler()\n",
    "scaler = StandardScaler()\n",
    "train_myscaled = myscaler.fit_transform(train_df[rooms])\n",
    "train_scaled = scaler.fit_transform(train_df[rooms])\n",
    "\n",
    "if np.array_equal(train_myscaled, train_scaled):\n",
    "    print(\"Результат нормализации идентичен\")\n",
    "else:\n",
    "    print(\"Нормализация различается\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfac2239",
   "metadata": {},
   "source": [
    "### 7. Fit custom and sklearn models with normalized data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142416a7",
   "metadata": {},
   "source": [
    "a. Fit all models — Linear Regression, Ridge, Lasso, and ElasticNet — with MinMaxScaler.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89953cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.a\n",
    "\n",
    "# my_mimax = MinMaxScaler()\n",
    "my_mimax = MyMinMaxScaler()\n",
    "my_mimax.fit(train_df[rooms])\n",
    "\n",
    "train_df_minmax, test_df_minmax = train_df.copy(), test_df.copy()\n",
    "\n",
    "train_df_minmax[rooms] = my_mimax.transform(train_df[rooms])\n",
    "test_df_minmax[rooms] = my_mimax.transform(test_df[rooms])\n",
    "\n",
    "metrics[\"MyLinearRegression__MinMaxScaler\"] = show_metrics(\n",
    "     MyLinearRegression(),\n",
    "     train_df_minmax,\n",
    "     test_df_minmax,\n",
    "     most_common,\n",
    "     target\n",
    ")\n",
    "metrics[\"LinearRegression__MinMaxScaler\"] = show_metrics(\n",
    "     LinearRegression(),\n",
    "     train_df_minmax,\n",
    "     test_df_minmax,\n",
    "     most_common,\n",
    "     target\n",
    ")\n",
    "metrics[\"MyRidge__MinMaxScaler\"] = show_metrics(\n",
    "     MyRidge(),\n",
    "     train_df_minmax,\n",
    "     test_df_minmax,\n",
    "     most_common,\n",
    "     target\n",
    ")\n",
    "metrics[\"Ridge__MinMaxScaler\"] = show_metrics(\n",
    "     Ridge(random_state=21),\n",
    "     train_df_minmax,\n",
    "     test_df_minmax,\n",
    "     most_common,\n",
    "     target\n",
    ")\n",
    "metrics[\"MyLasso__MinMaxScaler\"] = show_metrics(\n",
    "     MyLasso(),\n",
    "     train_df_minmax,\n",
    "     test_df_minmax,\n",
    "     most_common,\n",
    "     target\n",
    ")\n",
    "metrics[\"Lasso__MinMaxScaler\"] = show_metrics(\n",
    "     Lasso(random_state=21),\n",
    "     train_df_minmax,\n",
    "     test_df_minmax,\n",
    "     most_common,\n",
    "     target\n",
    ")\n",
    "metrics[\"MyElasticNet__MinMaxScaler\"] = show_metrics(\n",
    "     MyElasticNet(),\n",
    "     train_df_minmax,\n",
    "     test_df_minmax,\n",
    "     most_common,\n",
    "     target\n",
    ")\n",
    "metrics[\"ElasticNet__MinMaxScaler\"] = show_metrics(\n",
    "     ElasticNet(random_state=21),\n",
    "     train_df_minmax,\n",
    "     test_df_minmax,\n",
    "     most_common,\n",
    "     target\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fa2830",
   "metadata": {},
   "source": [
    "b. Fit all models — Linear Regression, Ridge, Lasso, and ElasticNet — with StandardScaler.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a358cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.b\n",
    "\n",
    "# my_scaler = StandardScaler()\n",
    "my_scaler = MyStandardScaler()\n",
    "my_scaler.fit(train_df[rooms])\n",
    "\n",
    "train_df_scaler, test_df_scaler = train_df.copy(), test_df.copy()\n",
    "\n",
    "train_df_scaler[rooms] = my_scaler.transform(train_df[rooms])\n",
    "test_df_scaler[rooms] = my_scaler.transform(test_df[rooms])\n",
    "\n",
    "metrics[\"MyLinearRegression__StandartScaler\"] = show_metrics(\n",
    "    MyLinearRegression(),\n",
    "    train_df_scaler,\n",
    "    test_df_scaler,\n",
    "    most_common,\n",
    "    target\n",
    ")\n",
    "metrics[\"LinearRegression__StandartScaler\"] = show_metrics(\n",
    "    LinearRegression(),\n",
    "    train_df_scaler,\n",
    "    test_df_scaler,\n",
    "    most_common,\n",
    "    target\n",
    ")\n",
    "metrics[\"MyRidge__StandartScaler\"] = show_metrics(\n",
    "    MyRidge(),\n",
    "    train_df_scaler,\n",
    "    test_df_scaler,\n",
    "    most_common,\n",
    "    target\n",
    ")\n",
    "metrics[\"Ridge__StandartScaler\"] = show_metrics(\n",
    "    Ridge(random_state=21),\n",
    "    train_df_scaler,\n",
    "    test_df_scaler,\n",
    "    most_common,\n",
    "    target\n",
    ")\n",
    "metrics[\"MyLasso__StandartScaler\"] = show_metrics(\n",
    "    MyLasso(),\n",
    "    train_df_scaler,\n",
    "    test_df_scaler,\n",
    "    most_common,\n",
    "    target\n",
    ")\n",
    "metrics[\"Lasso__StandartScaler\"] = show_metrics(\n",
    "    Lasso(random_state=21),\n",
    "    train_df_scaler,\n",
    "    test_df_scaler,\n",
    "    most_common,\n",
    "    target\n",
    ")\n",
    "metrics[\"MyElasticNet__StandartScaler\"] = show_metrics(\n",
    "    MyElasticNet(),\n",
    "    train_df_scaler,\n",
    "    test_df_scaler,\n",
    "    most_common,\n",
    "    target\n",
    ")\n",
    "metrics[\"ElasticNet__StandartScaler\"] = show_metrics(\n",
    "    ElasticNet(random_state=21),\n",
    "    train_df_scaler,\n",
    "    test_df_scaler,\n",
    "    most_common,\n",
    "    target\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5631b3db",
   "metadata": {},
   "source": [
    "c. Add all results to our dataframe with metrics on samples.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b17fca16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">mae</th>\n",
       "      <th>MyLasso__StandartScaler</th>\n",
       "      <td>710.551273</td>\n",
       "      <td>703.782587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso</th>\n",
       "      <td>710.935537</td>\n",
       "      <td>704.009476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__StandartScaler</th>\n",
       "      <td>714.699581</td>\n",
       "      <td>707.583526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__StandartScaler</th>\n",
       "      <td>741.792851</td>\n",
       "      <td>736.032475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge</th>\n",
       "      <td>741.794252</td>\n",
       "      <td>736.033898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression</th>\n",
       "      <td>760.580005</td>\n",
       "      <td>755.121589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__MinMaxScaler</th>\n",
       "      <td>761.017063</td>\n",
       "      <td>755.751588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__StandartScaler</th>\n",
       "      <td>786.600099</td>\n",
       "      <td>781.020666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet</th>\n",
       "      <td>802.731810</td>\n",
       "      <td>797.985764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__MinMaxScaler</th>\n",
       "      <td>880.084792</td>\n",
       "      <td>877.383016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__MinMaxScaler</th>\n",
       "      <td>1046.548047</td>\n",
       "      <td>1045.271885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__MinMaxScaler</th>\n",
       "      <td>1151.998267</td>\n",
       "      <td>1146.513362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                                          train         test\n",
       "metric model                                                       \n",
       "mae    MyLasso__StandartScaler              710.551273   703.782587\n",
       "       MyLasso                              710.935537   704.009476\n",
       "       MyLinearRegression__StandartScaler   714.699581   707.583526\n",
       "       MyRidge__StandartScaler              741.792851   736.032475\n",
       "       MyRidge                              741.794252   736.033898\n",
       "       MyLinearRegression                   760.580005   755.121589\n",
       "       MyRidge__MinMaxScaler                761.017063   755.751588\n",
       "       MyElasticNet__StandartScaler         786.600099   781.020666\n",
       "       MyElasticNet                         802.731810   797.985764\n",
       "       MyLasso__MinMaxScaler                880.084792   877.383016\n",
       "       MyElasticNet__MinMaxScaler          1046.548047  1045.271885\n",
       "       MyLinearRegression__MinMaxScaler    1151.998267  1146.513362"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">rmse</th>\n",
       "      <th>MyLinearRegression__StandartScaler</th>\n",
       "      <td>1180.251240</td>\n",
       "      <td>1028.166643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso</th>\n",
       "      <td>1190.402330</td>\n",
       "      <td>1029.196327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__StandartScaler</th>\n",
       "      <td>1193.527937</td>\n",
       "      <td>1033.389819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression</th>\n",
       "      <td>1212.694679</td>\n",
       "      <td>1048.465824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__StandartScaler</th>\n",
       "      <td>1118.153174</td>\n",
       "      <td>1070.384642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge</th>\n",
       "      <td>1118.153174</td>\n",
       "      <td>1070.386872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__MinMaxScaler</th>\n",
       "      <td>1126.468117</td>\n",
       "      <td>1101.659753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__StandartScaler</th>\n",
       "      <td>1204.448435</td>\n",
       "      <td>1151.125618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet</th>\n",
       "      <td>1217.781706</td>\n",
       "      <td>1197.739219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__MinMaxScaler</th>\n",
       "      <td>1318.166611</td>\n",
       "      <td>1313.715682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__MinMaxScaler</th>\n",
       "      <td>1501.594264</td>\n",
       "      <td>1495.865708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__MinMaxScaler</th>\n",
       "      <td>1660.592958</td>\n",
       "      <td>1653.872789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                                          train         test\n",
       "metric model                                                       \n",
       "rmse   MyLinearRegression__StandartScaler  1180.251240  1028.166643\n",
       "       MyLasso                             1190.402330  1029.196327\n",
       "       MyLasso__StandartScaler             1193.527937  1033.389819\n",
       "       MyLinearRegression                  1212.694679  1048.465824\n",
       "       MyRidge__StandartScaler             1118.153174  1070.384642\n",
       "       MyRidge                             1118.153174  1070.386872\n",
       "       MyRidge__MinMaxScaler               1126.468117  1101.659753\n",
       "       MyElasticNet__StandartScaler        1204.448435  1151.125618\n",
       "       MyElasticNet                        1217.781706  1197.739219\n",
       "       MyLasso__MinMaxScaler               1318.166611  1313.715682\n",
       "       MyElasticNet__MinMaxScaler          1501.594264  1495.865708\n",
       "       MyLinearRegression__MinMaxScaler    1660.592958  1653.872789"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">r2_score</th>\n",
       "      <th>MyLinearRegression__StandartScaler</th>\n",
       "      <td>0.452061</td>\n",
       "      <td>0.581170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso</th>\n",
       "      <td>0.442595</td>\n",
       "      <td>0.580331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__StandartScaler</th>\n",
       "      <td>0.439664</td>\n",
       "      <td>0.576904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression</th>\n",
       "      <td>0.421523</td>\n",
       "      <td>0.564469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__StandartScaler</th>\n",
       "      <td>0.508203</td>\n",
       "      <td>0.546068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge</th>\n",
       "      <td>0.508203</td>\n",
       "      <td>0.546066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__MinMaxScaler</th>\n",
       "      <td>0.500862</td>\n",
       "      <td>0.519154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__StandartScaler</th>\n",
       "      <td>0.429364</td>\n",
       "      <td>0.475004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet</th>\n",
       "      <td>0.416660</td>\n",
       "      <td>0.431624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__MinMaxScaler</th>\n",
       "      <td>0.316523</td>\n",
       "      <td>0.316224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__MinMaxScaler</th>\n",
       "      <td>0.113072</td>\n",
       "      <td>0.113465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__MinMaxScaler</th>\n",
       "      <td>-0.084699</td>\n",
       "      <td>-0.083715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                                         train      test\n",
       "metric   model                                                 \n",
       "r2_score MyLinearRegression__StandartScaler  0.452061  0.581170\n",
       "         MyLasso                             0.442595  0.580331\n",
       "         MyLasso__StandartScaler             0.439664  0.576904\n",
       "         MyLinearRegression                  0.421523  0.564469\n",
       "         MyRidge__StandartScaler             0.508203  0.546068\n",
       "         MyRidge                             0.508203  0.546066\n",
       "         MyRidge__MinMaxScaler               0.500862  0.519154\n",
       "         MyElasticNet__StandartScaler        0.429364  0.475004\n",
       "         MyElasticNet                        0.416660  0.431624\n",
       "         MyLasso__MinMaxScaler               0.316523  0.316224\n",
       "         MyElasticNet__MinMaxScaler          0.113072  0.113465\n",
       "         MyLinearRegression__MinMaxScaler   -0.084699 -0.083715"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7.c\n",
    "\n",
    "metrics_df7 = get_scores_df(metrics)\n",
    "mask = metrics_df7.index.get_level_values('model').str.startswith('My')\n",
    "display(\n",
    "    metrics_df7[mask].loc[[\"mae\"]].sort_values(by=\"test\", ascending=True),\n",
    "    metrics_df7[mask].loc[[\"rmse\"]].sort_values(by=\"test\", ascending=True),\n",
    "    metrics_df7[mask].loc[[\"r2_score\"]].sort_values(by=\"test\", ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0563c46a",
   "metadata": {},
   "source": [
    "### 8. Overfit models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccf6210",
   "metadata": {},
   "source": [
    "a. Let's look at an overfitted model in practice. From theory, you know that polynomial regression is easy to overfit. So let's create a toy example and see how regularization works in real life.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c90b445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.a\n",
    "\n",
    "my_mimax = MyMinMaxScaler()\n",
    "my_mimax.fit(train_df[rooms])\n",
    "train_df[rooms], test_df[rooms] = my_mimax.transform(train_df[rooms]), my_mimax.transform(test_df[rooms])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c245cdb6",
   "metadata": {},
   "source": [
    "b. In the previous lesson, we created polynomial features with degree 10. Here we repeat these steps from the previous lesson, remembering that we have only 2 basic features — 'bathrooms' and 'bedrooms'.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d019ae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.b\n",
    "\n",
    "poly = PolynomialFeatures(degree=10, include_bias=False)\n",
    "poly.fit(train_df[rooms])\n",
    "poly_features = poly.get_feature_names_out()\n",
    "\n",
    "most_common_poly = most_common.copy()\n",
    "most_common_poly.extend(poly_features)\n",
    "\n",
    "train_df[poly_features] = poly.transform(train_df[rooms])\n",
    "test_df[poly_features] = poly.transform(test_df[rooms])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8873f51",
   "metadata": {},
   "source": [
    "c. And train and fit all our implemented algorithms — Linear Regression, Ridge, Lasso, and ElasticNet — on a set of polynomial features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf8c50a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.c\n",
    "\n",
    "metrics[\"MyLinearRegression__Polynomial\"] = show_metrics(\n",
    "     MyLinearRegression(),\n",
    "     train_df,\n",
    "     test_df,\n",
    "     poly_features,\n",
    "     target\n",
    ")\n",
    "metrics[\"LinearRegression__Polynomial\"] = show_metrics(\n",
    "     LinearRegression(),\n",
    "     train_df,\n",
    "     test_df,\n",
    "     poly_features,\n",
    "     target\n",
    ")\n",
    "metrics[\"MyRidge__Polynomial\"] = show_metrics(\n",
    "     MyRidge(),\n",
    "     train_df,\n",
    "     test_df,\n",
    "     poly_features,\n",
    "     target\n",
    ")\n",
    "metrics[\"Ridge__Polynomial\"] = show_metrics(\n",
    "     Ridge(random_state=21),\n",
    "     train_df,\n",
    "     test_df,\n",
    "     poly_features,\n",
    "     target\n",
    ")\n",
    "metrics[\"MyLasso__Polynomial\"] = show_metrics(\n",
    "     MyLasso(),\n",
    "     train_df,\n",
    "     test_df,\n",
    "     poly_features,\n",
    "     target\n",
    ")\n",
    "metrics[\"Lasso__Polynomial\"] = show_metrics(\n",
    "     Lasso(random_state=21),\n",
    "     train_df,\n",
    "     test_df,\n",
    "     poly_features,\n",
    "     target\n",
    ")\n",
    "metrics[\"MyElasticNet__Polynomial\"] = show_metrics(\n",
    "     MyElasticNet(),\n",
    "     train_df,\n",
    "     test_df,\n",
    "     poly_features,\n",
    "     target\n",
    ")\n",
    "metrics[\"ElasticNet__Polynomial\"] = show_metrics(\n",
    "     ElasticNet(random_state=21),\n",
    "     train_df,\n",
    "     test_df,\n",
    "     poly_features,\n",
    "     target\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d842515",
   "metadata": {},
   "source": [
    "d. Store the results of the quality metrics in the result dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a63f67db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.d\n",
    "\n",
    "metrics_df8 = get_scores_df(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05eedde4",
   "metadata": {},
   "source": [
    "e. Analyze the results and select the best model according to your opinion.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af0d1f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"16\" valign=\"top\">mae</th>\n",
       "      <th>MyLasso__StandartScaler</th>\n",
       "      <td>710.551273</td>\n",
       "      <td>703.782587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso</th>\n",
       "      <td>710.935537</td>\n",
       "      <td>704.009476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__StandartScaler</th>\n",
       "      <td>714.699581</td>\n",
       "      <td>707.583526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__StandartScaler</th>\n",
       "      <td>741.792851</td>\n",
       "      <td>736.032475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge</th>\n",
       "      <td>741.794252</td>\n",
       "      <td>736.033898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression</th>\n",
       "      <td>760.580005</td>\n",
       "      <td>755.121589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__MinMaxScaler</th>\n",
       "      <td>761.017063</td>\n",
       "      <td>755.751588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__StandartScaler</th>\n",
       "      <td>786.600099</td>\n",
       "      <td>781.020666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet</th>\n",
       "      <td>802.731810</td>\n",
       "      <td>797.985764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__Polynomial</th>\n",
       "      <td>814.399088</td>\n",
       "      <td>810.589343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__MinMaxScaler</th>\n",
       "      <td>880.084792</td>\n",
       "      <td>877.383016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__Polynomial</th>\n",
       "      <td>974.045141</td>\n",
       "      <td>971.405211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__Polynomial</th>\n",
       "      <td>983.530588</td>\n",
       "      <td>980.428100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__MinMaxScaler</th>\n",
       "      <td>1046.548047</td>\n",
       "      <td>1045.271885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__Polynomial</th>\n",
       "      <td>1113.876698</td>\n",
       "      <td>1111.618344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__MinMaxScaler</th>\n",
       "      <td>1151.998267</td>\n",
       "      <td>1146.513362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                                          train         test\n",
       "metric model                                                       \n",
       "mae    MyLasso__StandartScaler              710.551273   703.782587\n",
       "       MyLasso                              710.935537   704.009476\n",
       "       MyLinearRegression__StandartScaler   714.699581   707.583526\n",
       "       MyRidge__StandartScaler              741.792851   736.032475\n",
       "       MyRidge                              741.794252   736.033898\n",
       "       MyLinearRegression                   760.580005   755.121589\n",
       "       MyRidge__MinMaxScaler                761.017063   755.751588\n",
       "       MyElasticNet__StandartScaler         786.600099   781.020666\n",
       "       MyElasticNet                         802.731810   797.985764\n",
       "       MyRidge__Polynomial                  814.399088   810.589343\n",
       "       MyLasso__MinMaxScaler                880.084792   877.383016\n",
       "       MyLinearRegression__Polynomial       974.045141   971.405211\n",
       "       MyLasso__Polynomial                  983.530588   980.428100\n",
       "       MyElasticNet__MinMaxScaler          1046.548047  1045.271885\n",
       "       MyElasticNet__Polynomial            1113.876698  1111.618344\n",
       "       MyLinearRegression__MinMaxScaler    1151.998267  1146.513362"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"16\" valign=\"top\">rmse</th>\n",
       "      <th>MyLinearRegression__StandartScaler</th>\n",
       "      <td>1180.251240</td>\n",
       "      <td>1028.166643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso</th>\n",
       "      <td>1190.402330</td>\n",
       "      <td>1029.196327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__StandartScaler</th>\n",
       "      <td>1193.527937</td>\n",
       "      <td>1033.389819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression</th>\n",
       "      <td>1212.694679</td>\n",
       "      <td>1048.465824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__StandartScaler</th>\n",
       "      <td>1118.153174</td>\n",
       "      <td>1070.384642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge</th>\n",
       "      <td>1118.153174</td>\n",
       "      <td>1070.386872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__MinMaxScaler</th>\n",
       "      <td>1126.468117</td>\n",
       "      <td>1101.659753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__StandartScaler</th>\n",
       "      <td>1204.448435</td>\n",
       "      <td>1151.125618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__Polynomial</th>\n",
       "      <td>1182.725653</td>\n",
       "      <td>1171.385294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet</th>\n",
       "      <td>1217.781706</td>\n",
       "      <td>1197.739219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__MinMaxScaler</th>\n",
       "      <td>1318.166611</td>\n",
       "      <td>1313.715682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__Polynomial</th>\n",
       "      <td>1387.405854</td>\n",
       "      <td>1381.979562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__Polynomial</th>\n",
       "      <td>1423.981753</td>\n",
       "      <td>1417.831280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__MinMaxScaler</th>\n",
       "      <td>1501.594264</td>\n",
       "      <td>1495.865708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__Polynomial</th>\n",
       "      <td>1574.415277</td>\n",
       "      <td>1568.446903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__MinMaxScaler</th>\n",
       "      <td>1660.592958</td>\n",
       "      <td>1653.872789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                                          train         test\n",
       "metric model                                                       \n",
       "rmse   MyLinearRegression__StandartScaler  1180.251240  1028.166643\n",
       "       MyLasso                             1190.402330  1029.196327\n",
       "       MyLasso__StandartScaler             1193.527937  1033.389819\n",
       "       MyLinearRegression                  1212.694679  1048.465824\n",
       "       MyRidge__StandartScaler             1118.153174  1070.384642\n",
       "       MyRidge                             1118.153174  1070.386872\n",
       "       MyRidge__MinMaxScaler               1126.468117  1101.659753\n",
       "       MyElasticNet__StandartScaler        1204.448435  1151.125618\n",
       "       MyRidge__Polynomial                 1182.725653  1171.385294\n",
       "       MyElasticNet                        1217.781706  1197.739219\n",
       "       MyLasso__MinMaxScaler               1318.166611  1313.715682\n",
       "       MyLinearRegression__Polynomial      1387.405854  1381.979562\n",
       "       MyLasso__Polynomial                 1423.981753  1417.831280\n",
       "       MyElasticNet__MinMaxScaler          1501.594264  1495.865708\n",
       "       MyElasticNet__Polynomial            1574.415277  1568.446903\n",
       "       MyLinearRegression__MinMaxScaler    1660.592958  1653.872789"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"16\" valign=\"top\">r2_score</th>\n",
       "      <th>MyLinearRegression__StandartScaler</th>\n",
       "      <td>0.452061</td>\n",
       "      <td>0.581170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso</th>\n",
       "      <td>0.442595</td>\n",
       "      <td>0.580331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__StandartScaler</th>\n",
       "      <td>0.439664</td>\n",
       "      <td>0.576904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression</th>\n",
       "      <td>0.421523</td>\n",
       "      <td>0.564469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__StandartScaler</th>\n",
       "      <td>0.508203</td>\n",
       "      <td>0.546068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge</th>\n",
       "      <td>0.508203</td>\n",
       "      <td>0.546066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__MinMaxScaler</th>\n",
       "      <td>0.500862</td>\n",
       "      <td>0.519154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__StandartScaler</th>\n",
       "      <td>0.429364</td>\n",
       "      <td>0.475004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__Polynomial</th>\n",
       "      <td>0.449761</td>\n",
       "      <td>0.456361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet</th>\n",
       "      <td>0.416660</td>\n",
       "      <td>0.431624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__MinMaxScaler</th>\n",
       "      <td>0.316523</td>\n",
       "      <td>0.316224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__Polynomial</th>\n",
       "      <td>0.242836</td>\n",
       "      <td>0.243317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__Polynomial</th>\n",
       "      <td>0.202388</td>\n",
       "      <td>0.203547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__MinMaxScaler</th>\n",
       "      <td>0.113072</td>\n",
       "      <td>0.113465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__Polynomial</th>\n",
       "      <td>0.024962</td>\n",
       "      <td>0.025346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__MinMaxScaler</th>\n",
       "      <td>-0.084699</td>\n",
       "      <td>-0.083715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                                         train      test\n",
       "metric   model                                                 \n",
       "r2_score MyLinearRegression__StandartScaler  0.452061  0.581170\n",
       "         MyLasso                             0.442595  0.580331\n",
       "         MyLasso__StandartScaler             0.439664  0.576904\n",
       "         MyLinearRegression                  0.421523  0.564469\n",
       "         MyRidge__StandartScaler             0.508203  0.546068\n",
       "         MyRidge                             0.508203  0.546066\n",
       "         MyRidge__MinMaxScaler               0.500862  0.519154\n",
       "         MyElasticNet__StandartScaler        0.429364  0.475004\n",
       "         MyRidge__Polynomial                 0.449761  0.456361\n",
       "         MyElasticNet                        0.416660  0.431624\n",
       "         MyLasso__MinMaxScaler               0.316523  0.316224\n",
       "         MyLinearRegression__Polynomial      0.242836  0.243317\n",
       "         MyLasso__Polynomial                 0.202388  0.203547\n",
       "         MyElasticNet__MinMaxScaler          0.113072  0.113465\n",
       "         MyElasticNet__Polynomial            0.024962  0.025346\n",
       "         MyLinearRegression__MinMaxScaler   -0.084699 -0.083715"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 8.e\n",
    "\n",
    "mask = metrics_df8.index.get_level_values('model').str.startswith('My')\n",
    "display(\n",
    "    metrics_df8[mask].loc[[\"mae\"]].sort_values(by=\"test\", ascending=True),\n",
    "    metrics_df8[mask].loc[[\"rmse\"]].sort_values(by=\"test\", ascending=True),\n",
    "    metrics_df8[mask].loc[[\"r2_score\"]].sort_values(by=\"test\", ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecec34d",
   "metadata": {},
   "source": [
    "f. Additionally try different alpha parameters of regularization in algorithms, choose the best one and analyze results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b7dca3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"16\" valign=\"top\">mae</th>\n",
       "      <th>MyLasso__StandartScaler</th>\n",
       "      <td>710.551273</td>\n",
       "      <td>703.782587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso</th>\n",
       "      <td>710.935537</td>\n",
       "      <td>704.009476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__StandartScaler</th>\n",
       "      <td>714.699581</td>\n",
       "      <td>707.583526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__StandartScaler</th>\n",
       "      <td>741.792851</td>\n",
       "      <td>736.032475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge</th>\n",
       "      <td>741.794252</td>\n",
       "      <td>736.033898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression</th>\n",
       "      <td>760.580005</td>\n",
       "      <td>755.121589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__MinMaxScaler</th>\n",
       "      <td>761.017063</td>\n",
       "      <td>755.751588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__StandartScaler</th>\n",
       "      <td>786.600099</td>\n",
       "      <td>781.020666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet</th>\n",
       "      <td>802.731810</td>\n",
       "      <td>797.985764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__Polynomial</th>\n",
       "      <td>808.491145</td>\n",
       "      <td>804.742414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__MinMaxScaler</th>\n",
       "      <td>880.084792</td>\n",
       "      <td>877.383016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__Polynomial</th>\n",
       "      <td>974.045141</td>\n",
       "      <td>971.405211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__Polynomial</th>\n",
       "      <td>983.403588</td>\n",
       "      <td>980.300572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__MinMaxScaler</th>\n",
       "      <td>1046.548047</td>\n",
       "      <td>1045.271885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__Polynomial</th>\n",
       "      <td>1109.541712</td>\n",
       "      <td>1107.256688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__MinMaxScaler</th>\n",
       "      <td>1151.998267</td>\n",
       "      <td>1146.513362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                                          train         test\n",
       "metric model                                                       \n",
       "mae    MyLasso__StandartScaler              710.551273   703.782587\n",
       "       MyLasso                              710.935537   704.009476\n",
       "       MyLinearRegression__StandartScaler   714.699581   707.583526\n",
       "       MyRidge__StandartScaler              741.792851   736.032475\n",
       "       MyRidge                              741.794252   736.033898\n",
       "       MyLinearRegression                   760.580005   755.121589\n",
       "       MyRidge__MinMaxScaler                761.017063   755.751588\n",
       "       MyElasticNet__StandartScaler         786.600099   781.020666\n",
       "       MyElasticNet                         802.731810   797.985764\n",
       "       MyRidge__Polynomial                  808.491145   804.742414\n",
       "       MyLasso__MinMaxScaler                880.084792   877.383016\n",
       "       MyLinearRegression__Polynomial       974.045141   971.405211\n",
       "       MyLasso__Polynomial                  983.403588   980.300572\n",
       "       MyElasticNet__MinMaxScaler          1046.548047  1045.271885\n",
       "       MyElasticNet__Polynomial            1109.541712  1107.256688\n",
       "       MyLinearRegression__MinMaxScaler    1151.998267  1146.513362"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"16\" valign=\"top\">rmse</th>\n",
       "      <th>MyLinearRegression__StandartScaler</th>\n",
       "      <td>1180.251240</td>\n",
       "      <td>1028.166643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso</th>\n",
       "      <td>1190.402330</td>\n",
       "      <td>1029.196327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__StandartScaler</th>\n",
       "      <td>1193.527937</td>\n",
       "      <td>1033.389819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression</th>\n",
       "      <td>1212.694679</td>\n",
       "      <td>1048.465824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__StandartScaler</th>\n",
       "      <td>1118.153174</td>\n",
       "      <td>1070.384642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge</th>\n",
       "      <td>1118.153174</td>\n",
       "      <td>1070.386872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__MinMaxScaler</th>\n",
       "      <td>1126.468117</td>\n",
       "      <td>1101.659753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__StandartScaler</th>\n",
       "      <td>1204.448435</td>\n",
       "      <td>1151.125618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__Polynomial</th>\n",
       "      <td>1172.613404</td>\n",
       "      <td>1160.409503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet</th>\n",
       "      <td>1217.781706</td>\n",
       "      <td>1197.739219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__MinMaxScaler</th>\n",
       "      <td>1318.166611</td>\n",
       "      <td>1313.715682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__Polynomial</th>\n",
       "      <td>1387.405854</td>\n",
       "      <td>1381.979562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__Polynomial</th>\n",
       "      <td>1423.831659</td>\n",
       "      <td>1417.680159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__MinMaxScaler</th>\n",
       "      <td>1501.594264</td>\n",
       "      <td>1495.865708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__Polynomial</th>\n",
       "      <td>1569.460236</td>\n",
       "      <td>1563.477979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__MinMaxScaler</th>\n",
       "      <td>1660.592958</td>\n",
       "      <td>1653.872789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                                          train         test\n",
       "metric model                                                       \n",
       "rmse   MyLinearRegression__StandartScaler  1180.251240  1028.166643\n",
       "       MyLasso                             1190.402330  1029.196327\n",
       "       MyLasso__StandartScaler             1193.527937  1033.389819\n",
       "       MyLinearRegression                  1212.694679  1048.465824\n",
       "       MyRidge__StandartScaler             1118.153174  1070.384642\n",
       "       MyRidge                             1118.153174  1070.386872\n",
       "       MyRidge__MinMaxScaler               1126.468117  1101.659753\n",
       "       MyElasticNet__StandartScaler        1204.448435  1151.125618\n",
       "       MyRidge__Polynomial                 1172.613404  1160.409503\n",
       "       MyElasticNet                        1217.781706  1197.739219\n",
       "       MyLasso__MinMaxScaler               1318.166611  1313.715682\n",
       "       MyLinearRegression__Polynomial      1387.405854  1381.979562\n",
       "       MyLasso__Polynomial                 1423.831659  1417.680159\n",
       "       MyElasticNet__MinMaxScaler          1501.594264  1495.865708\n",
       "       MyElasticNet__Polynomial            1569.460236  1563.477979\n",
       "       MyLinearRegression__MinMaxScaler    1660.592958  1653.872789"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"16\" valign=\"top\">r2_score</th>\n",
       "      <th>MyLinearRegression__StandartScaler</th>\n",
       "      <td>0.452061</td>\n",
       "      <td>0.581170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso</th>\n",
       "      <td>0.442595</td>\n",
       "      <td>0.580331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__StandartScaler</th>\n",
       "      <td>0.439664</td>\n",
       "      <td>0.576904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression</th>\n",
       "      <td>0.421523</td>\n",
       "      <td>0.564469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__StandartScaler</th>\n",
       "      <td>0.508203</td>\n",
       "      <td>0.546068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge</th>\n",
       "      <td>0.508203</td>\n",
       "      <td>0.546066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__MinMaxScaler</th>\n",
       "      <td>0.500862</td>\n",
       "      <td>0.519154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__StandartScaler</th>\n",
       "      <td>0.429364</td>\n",
       "      <td>0.475004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__Polynomial</th>\n",
       "      <td>0.459130</td>\n",
       "      <td>0.466501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet</th>\n",
       "      <td>0.416660</td>\n",
       "      <td>0.431624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__MinMaxScaler</th>\n",
       "      <td>0.316523</td>\n",
       "      <td>0.316224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__Polynomial</th>\n",
       "      <td>0.242836</td>\n",
       "      <td>0.243317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__Polynomial</th>\n",
       "      <td>0.202556</td>\n",
       "      <td>0.203717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__MinMaxScaler</th>\n",
       "      <td>0.113072</td>\n",
       "      <td>0.113465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__Polynomial</th>\n",
       "      <td>0.031089</td>\n",
       "      <td>0.031512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__MinMaxScaler</th>\n",
       "      <td>-0.084699</td>\n",
       "      <td>-0.083715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                                         train      test\n",
       "metric   model                                                 \n",
       "r2_score MyLinearRegression__StandartScaler  0.452061  0.581170\n",
       "         MyLasso                             0.442595  0.580331\n",
       "         MyLasso__StandartScaler             0.439664  0.576904\n",
       "         MyLinearRegression                  0.421523  0.564469\n",
       "         MyRidge__StandartScaler             0.508203  0.546068\n",
       "         MyRidge                             0.508203  0.546066\n",
       "         MyRidge__MinMaxScaler               0.500862  0.519154\n",
       "         MyElasticNet__StandartScaler        0.429364  0.475004\n",
       "         MyRidge__Polynomial                 0.459130  0.466501\n",
       "         MyElasticNet                        0.416660  0.431624\n",
       "         MyLasso__MinMaxScaler               0.316523  0.316224\n",
       "         MyLinearRegression__Polynomial      0.242836  0.243317\n",
       "         MyLasso__Polynomial                 0.202556  0.203717\n",
       "         MyElasticNet__MinMaxScaler          0.113072  0.113465\n",
       "         MyElasticNet__Polynomial            0.031089  0.031512\n",
       "         MyLinearRegression__MinMaxScaler   -0.084699 -0.083715"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 8.f\n",
    "\n",
    "alpha=0.8\n",
    "\n",
    "metrics[\"MyRidge__Polynomial\"] = show_metrics(\n",
    "     MyRidge(alpha=alpha),\n",
    "     train_df,\n",
    "     test_df,\n",
    "     poly_features,\n",
    "     target\n",
    ")\n",
    "metrics[\"MyLasso__Polynomial\"] = show_metrics(\n",
    "     MyLasso(alpha=alpha),\n",
    "     train_df,\n",
    "     test_df,\n",
    "     poly_features,\n",
    "     target\n",
    ")\n",
    "metrics[\"MyElasticNet__Polynomial\"] = show_metrics(\n",
    "     MyElasticNet(alpha=alpha),\n",
    "     train_df,\n",
    "     test_df,\n",
    "     poly_features,\n",
    "     target\n",
    ")\n",
    "\n",
    "metrics_df8 = get_scores_df(metrics)\n",
    "mask = metrics_df8.index.get_level_values('model').str.startswith('My')\n",
    "display(\n",
    "    metrics_df8[mask].loc[[\"mae\"]].sort_values(by=\"test\", ascending=True),\n",
    "    metrics_df8[mask].loc[[\"rmse\"]].sort_values(by=\"test\", ascending=True),\n",
    "    metrics_df8[mask].loc[[\"r2_score\"]].sort_values(by=\"test\", ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60c5f8f",
   "metadata": {},
   "source": [
    "### 9. Native models\n",
    "\n",
    "a. Calculate the mean and median metrics from the previous lesson and add the results to the final dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8839dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.a\n",
    "\n",
    "train_df, test_df = train_test_split(df[most_common + target], random_state=21)\n",
    "\n",
    "y_train_mean_pred = np.full(len(train_df), train_df[target].mean())\n",
    "y_test_mean_pred = np.full(len(test_df), test_df[target].mean())\n",
    "\n",
    "metrics[\"MyNaive_Mean\"] = {\n",
    "    \"train\": {\n",
    "        \"mae\": MAE(train_df[target], y_train_mean_pred),\n",
    "        \"rmse\": RMSE(train_df[target], y_train_mean_pred),\n",
    "        \"r2_score\": r2_my(train_df[target], y_train_mean_pred),\n",
    "    },\n",
    "    \"test\": {\n",
    "        \"mae\": MAE(test_df[target], y_test_mean_pred),\n",
    "        \"rmse\": RMSE(test_df[target], y_test_mean_pred),\n",
    "        \"r2_score\": r2_my(test_df[target], y_test_mean_pred),\n",
    "    }\n",
    "}\n",
    "\n",
    "y_train_median_pred = np.full(len(train_df), train_df[target].median())\n",
    "y_test_median_pred = np.full(len(test_df), test_df[target].median())\n",
    "\n",
    "metrics[\"MyNaive_Median\"] = {\n",
    "    \"train\": {\n",
    "        \"mae\": MAE(train_df[target], y_train_median_pred),\n",
    "        \"rmse\": RMSE(train_df[target], y_train_median_pred),\n",
    "        \"r2_score\": r2_my(train_df[target], y_train_median_pred),\n",
    "    },\n",
    "    \"test\": {\n",
    "        \"mae\": MAE(test_df[target], y_test_median_pred),\n",
    "        \"rmse\": RMSE(test_df[target], y_test_median_pred),\n",
    "        \"r2_score\": r2_my(test_df[target], y_test_median_pred),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c715ca23",
   "metadata": {},
   "source": [
    "### 10. Compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffae169",
   "metadata": {},
   "source": [
    "a. Print your final tables  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eedcd2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">mae</th>\n",
       "      <th>MyLasso__StandartScaler</th>\n",
       "      <td>710.551273</td>\n",
       "      <td>703.782587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso</th>\n",
       "      <td>710.935537</td>\n",
       "      <td>704.009476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__StandartScaler</th>\n",
       "      <td>714.699581</td>\n",
       "      <td>707.583526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__StandartScaler</th>\n",
       "      <td>741.792851</td>\n",
       "      <td>736.032475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge</th>\n",
       "      <td>741.794252</td>\n",
       "      <td>736.033898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression</th>\n",
       "      <td>760.580005</td>\n",
       "      <td>755.121589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__MinMaxScaler</th>\n",
       "      <td>761.017063</td>\n",
       "      <td>755.751588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__StandartScaler</th>\n",
       "      <td>786.600099</td>\n",
       "      <td>781.020666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet</th>\n",
       "      <td>802.731810</td>\n",
       "      <td>797.985764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__Polynomial</th>\n",
       "      <td>808.491145</td>\n",
       "      <td>804.742414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__MinMaxScaler</th>\n",
       "      <td>880.084792</td>\n",
       "      <td>877.383016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__Polynomial</th>\n",
       "      <td>974.045141</td>\n",
       "      <td>971.405211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__Polynomial</th>\n",
       "      <td>983.403588</td>\n",
       "      <td>980.300572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__MinMaxScaler</th>\n",
       "      <td>1046.548047</td>\n",
       "      <td>1045.271885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyNaive_Median</th>\n",
       "      <td>1086.464379</td>\n",
       "      <td>1080.433196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__Polynomial</th>\n",
       "      <td>1109.541712</td>\n",
       "      <td>1107.256688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyNaive_Mean</th>\n",
       "      <td>1138.509128</td>\n",
       "      <td>1132.291189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__MinMaxScaler</th>\n",
       "      <td>1151.998267</td>\n",
       "      <td>1146.513362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                                          train         test\n",
       "metric model                                                       \n",
       "mae    MyLasso__StandartScaler              710.551273   703.782587\n",
       "       MyLasso                              710.935537   704.009476\n",
       "       MyLinearRegression__StandartScaler   714.699581   707.583526\n",
       "       MyRidge__StandartScaler              741.792851   736.032475\n",
       "       MyRidge                              741.794252   736.033898\n",
       "       MyLinearRegression                   760.580005   755.121589\n",
       "       MyRidge__MinMaxScaler                761.017063   755.751588\n",
       "       MyElasticNet__StandartScaler         786.600099   781.020666\n",
       "       MyElasticNet                         802.731810   797.985764\n",
       "       MyRidge__Polynomial                  808.491145   804.742414\n",
       "       MyLasso__MinMaxScaler                880.084792   877.383016\n",
       "       MyLinearRegression__Polynomial       974.045141   971.405211\n",
       "       MyLasso__Polynomial                  983.403588   980.300572\n",
       "       MyElasticNet__MinMaxScaler          1046.548047  1045.271885\n",
       "       MyNaive_Median                      1086.464379  1080.433196\n",
       "       MyElasticNet__Polynomial            1109.541712  1107.256688\n",
       "       MyNaive_Mean                        1138.509128  1132.291189\n",
       "       MyLinearRegression__MinMaxScaler    1151.998267  1146.513362"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">rmse</th>\n",
       "      <th>MyLinearRegression__StandartScaler</th>\n",
       "      <td>1180.251240</td>\n",
       "      <td>1028.166643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso</th>\n",
       "      <td>1190.402330</td>\n",
       "      <td>1029.196327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__StandartScaler</th>\n",
       "      <td>1193.527937</td>\n",
       "      <td>1033.389819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression</th>\n",
       "      <td>1212.694679</td>\n",
       "      <td>1048.465824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__StandartScaler</th>\n",
       "      <td>1118.153174</td>\n",
       "      <td>1070.384642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge</th>\n",
       "      <td>1118.153174</td>\n",
       "      <td>1070.386872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__MinMaxScaler</th>\n",
       "      <td>1126.468117</td>\n",
       "      <td>1101.659753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__StandartScaler</th>\n",
       "      <td>1204.448435</td>\n",
       "      <td>1151.125618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__Polynomial</th>\n",
       "      <td>1172.613404</td>\n",
       "      <td>1160.409503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet</th>\n",
       "      <td>1217.781706</td>\n",
       "      <td>1197.739219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__MinMaxScaler</th>\n",
       "      <td>1318.166611</td>\n",
       "      <td>1313.715682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__Polynomial</th>\n",
       "      <td>1387.405854</td>\n",
       "      <td>1381.979562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__Polynomial</th>\n",
       "      <td>1423.831659</td>\n",
       "      <td>1417.680159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__MinMaxScaler</th>\n",
       "      <td>1501.594264</td>\n",
       "      <td>1495.865708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__Polynomial</th>\n",
       "      <td>1569.460236</td>\n",
       "      <td>1563.477979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyNaive_Mean</th>\n",
       "      <td>1594.441048</td>\n",
       "      <td>1588.709802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyNaive_Median</th>\n",
       "      <td>1641.218588</td>\n",
       "      <td>1634.013599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__MinMaxScaler</th>\n",
       "      <td>1660.592958</td>\n",
       "      <td>1653.872789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                                          train         test\n",
       "metric model                                                       \n",
       "rmse   MyLinearRegression__StandartScaler  1180.251240  1028.166643\n",
       "       MyLasso                             1190.402330  1029.196327\n",
       "       MyLasso__StandartScaler             1193.527937  1033.389819\n",
       "       MyLinearRegression                  1212.694679  1048.465824\n",
       "       MyRidge__StandartScaler             1118.153174  1070.384642\n",
       "       MyRidge                             1118.153174  1070.386872\n",
       "       MyRidge__MinMaxScaler               1126.468117  1101.659753\n",
       "       MyElasticNet__StandartScaler        1204.448435  1151.125618\n",
       "       MyRidge__Polynomial                 1172.613404  1160.409503\n",
       "       MyElasticNet                        1217.781706  1197.739219\n",
       "       MyLasso__MinMaxScaler               1318.166611  1313.715682\n",
       "       MyLinearRegression__Polynomial      1387.405854  1381.979562\n",
       "       MyLasso__Polynomial                 1423.831659  1417.680159\n",
       "       MyElasticNet__MinMaxScaler          1501.594264  1495.865708\n",
       "       MyElasticNet__Polynomial            1569.460236  1563.477979\n",
       "       MyNaive_Mean                        1594.441048  1588.709802\n",
       "       MyNaive_Median                      1641.218588  1634.013599\n",
       "       MyLinearRegression__MinMaxScaler    1660.592958  1653.872789"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">r2_score</th>\n",
       "      <th>MyLinearRegression__StandartScaler</th>\n",
       "      <td>0.452061</td>\n",
       "      <td>0.581170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso</th>\n",
       "      <td>0.442595</td>\n",
       "      <td>0.580331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__StandartScaler</th>\n",
       "      <td>0.439664</td>\n",
       "      <td>0.576904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression</th>\n",
       "      <td>0.421523</td>\n",
       "      <td>0.564469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__StandartScaler</th>\n",
       "      <td>0.508203</td>\n",
       "      <td>0.546068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge</th>\n",
       "      <td>0.508203</td>\n",
       "      <td>0.546066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__MinMaxScaler</th>\n",
       "      <td>0.500862</td>\n",
       "      <td>0.519154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__StandartScaler</th>\n",
       "      <td>0.429364</td>\n",
       "      <td>0.475004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyRidge__Polynomial</th>\n",
       "      <td>0.459130</td>\n",
       "      <td>0.466501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet</th>\n",
       "      <td>0.416660</td>\n",
       "      <td>0.431624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__MinMaxScaler</th>\n",
       "      <td>0.316523</td>\n",
       "      <td>0.316224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__Polynomial</th>\n",
       "      <td>0.242836</td>\n",
       "      <td>0.243317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLasso__Polynomial</th>\n",
       "      <td>0.202556</td>\n",
       "      <td>0.203717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__MinMaxScaler</th>\n",
       "      <td>0.113072</td>\n",
       "      <td>0.113465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyElasticNet__Polynomial</th>\n",
       "      <td>0.031089</td>\n",
       "      <td>0.031512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyNaive_Mean</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyNaive_Median</th>\n",
       "      <td>-0.059536</td>\n",
       "      <td>-0.057845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MyLinearRegression__MinMaxScaler</th>\n",
       "      <td>-0.084699</td>\n",
       "      <td>-0.083715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                                         train      test\n",
       "metric   model                                                 \n",
       "r2_score MyLinearRegression__StandartScaler  0.452061  0.581170\n",
       "         MyLasso                             0.442595  0.580331\n",
       "         MyLasso__StandartScaler             0.439664  0.576904\n",
       "         MyLinearRegression                  0.421523  0.564469\n",
       "         MyRidge__StandartScaler             0.508203  0.546068\n",
       "         MyRidge                             0.508203  0.546066\n",
       "         MyRidge__MinMaxScaler               0.500862  0.519154\n",
       "         MyElasticNet__StandartScaler        0.429364  0.475004\n",
       "         MyRidge__Polynomial                 0.459130  0.466501\n",
       "         MyElasticNet                        0.416660  0.431624\n",
       "         MyLasso__MinMaxScaler               0.316523  0.316224\n",
       "         MyLinearRegression__Polynomial      0.242836  0.243317\n",
       "         MyLasso__Polynomial                 0.202556  0.203717\n",
       "         MyElasticNet__MinMaxScaler          0.113072  0.113465\n",
       "         MyElasticNet__Polynomial            0.031089  0.031512\n",
       "         MyNaive_Mean                        0.000000  0.000000\n",
       "         MyNaive_Median                     -0.059536 -0.057845\n",
       "         MyLinearRegression__MinMaxScaler   -0.084699 -0.083715"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 10.a\n",
    "\n",
    "metrics_df10 = get_scores_df(metrics).sort_values(by=\"model\")\n",
    "mask = metrics_df10.index.get_level_values('model').str.startswith('My')\n",
    "display(\n",
    "    metrics_df10[mask].loc[[\"mae\"]].sort_values(by=\"test\", ascending=True),\n",
    "    metrics_df10[mask].loc[[\"rmse\"]].sort_values(by=\"test\", ascending=True),\n",
    "    metrics_df10[mask].loc[[\"r2_score\"]].sort_values(by=\"test\", ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c508cc33",
   "metadata": {},
   "source": [
    "b. What is the best model?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c8c86b",
   "metadata": {},
   "source": [
    ">\\# 10.b\n",
    "\n",
    "Лучшая модель: `'MyLinearRegression__StandartScaler'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdc414d",
   "metadata": {},
   "source": [
    "c. Which is the most stable model?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e82ff48",
   "metadata": {},
   "source": [
    ">\\# 10.с\n",
    "\n",
    "Самая стабильная модель: `'MyLasso__MinMaxScaler'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a094c0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 11. Addition task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48127a7d",
   "metadata": {},
   "source": [
    "a. There are some tricks with the target variable for better model quality. If we have a distribution with a heavy tail, you can use a monotone function to \"improve\" the distribution. In practice, you can use logarithmic functions. We recommend that you do this exercise and compare the results. But don't forget to do the inverse transformation if you want to compare metrics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79f738b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, \"Лог-нормальное распределение 'price'\")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGzCAYAAADOnwhmAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUEJJREFUeJzt3XlYVOXiB/DvMMKwOSAii4GI4IJ7YirlQmmikmZaZi6goqYXyyXRuJVrRllulUveDOyquWX9uloq4paKa6KGRu5osmguI6CAzPv7w8u5DjMgjMPMwPl+nmeex3POO+e8M2fG+XLOuyiEEAJEREREMmZj6QoQERERWRoDEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERGRkerXr49hw4ZZuhpkAgxEZDYJCQlQKBQGH82bN7d09YioGqtfvz5mzJhh6WpUWFWtd1VUw9IVIPmZNWsW/P39peU5c+ZYsDZERMZLS0uDjQ2vLVQHDERkNsXzCPfq1QvBwcHS+q+//ho3btywVLWIiCpECIH79+/DwcEBKpXK0tUhE2GsJbMpLCwEACiVyseWffDgAWbPno2AgACoVCrUr18f//znP5Gfn69Trn79+gZvwY0cObLM/e/evRsKhQIbN27U2+bs7KzXJuDChQt47bXX4ObmBkdHR3To0AFbtmwxuM9169bhn//8J7y8vODk5IQ+ffrgypUrOmVDQ0OhUCjQt29fveO/+eabBm8jfvbZZ3j22WdRu3ZtODg4IDg42GD9gdJvT4aGhuqVOXr0aBnvFDBs2DA4Ozvrrd+4cSMUCgV2796ts37Dhg0IDg6Gg4MD3N3dMWTIEPz11196z//jjz/w6quvws3NDfb29mjbti1++umnMusCAJcuXYJCocBnn32GBQsWwM/PDw4ODujSpQt+//13nbInT57EsGHD0KBBA9jb28PLywsjRozA33//rbffv/76C1FRUahbty5UKhX8/f0xduxYFBQUACj7lq9CodC5rTFjxgwoFAr88ccfGDBgANRqNWrXro3x48fj/v37esdetWqV9J65ublh4MCBep+ZYqUdv+R5yM/Px/Tp0xEYGAiVSgVfX19MmTJF7ztU1mt79PMCALdv38aECRPg6+sLlUqFwMBAfPLJJ9BqtQbPT0nNmzfX2Wfxd6Zk3cPDw/XeU+DhORoxYgQ8PT2hUqnQrFkzfPPNNwbfp8cpfs179+7Fm2++idq1a0OtViMiIgK3bt3SKVu/fn289NJL2LZtG9q2bQsHBwd89dVX0raS/1/cvn0bEydORP369aFSqeDj44OIiAidP/wqcn7IPHiFiMym+IfFzs7usWVHjhyJlStX4tVXX8U777yDQ4cOIS4uDmfOnMEPP/ygU7Z169Z45513dNYFBgaarN5ZWVl49tlnkZeXh7fffhu1a9fGypUr0adPH2zcuBGvvPKKTvk5c+ZAoVBg6tSpyM7OxsKFC9GtWzekpKTAwcFBKmdvb48tW7YgOzsbHh4eAIB79+5h3bp1sLe316vHokWL0KdPHwwePBgFBQVYu3YtXnvtNWzevBnh4eEG675gwQK4u7tL9apsCQkJGD58OJ555hnExcUhKysLixYtwv79+3H8+HG4uroCAFJTU/Hcc8/hqaeewrvvvgsnJyesX78effv2xffff6/3nhry7bff4u7du4iOjsb9+/exaNEivPDCCzh16hQ8PT0BAImJibhw4QKGDx8OLy8vpKamYvny5UhNTcXBgwehUCgAANeuXUO7du1w+/ZtjB49Gk2aNMFff/2FjRs3Ii8vT+czW/KWb05ODsaOHWuwjgMGDED9+vURFxeHgwcP4vPPP8etW7fw7bffSmXmzJmDDz74AAMGDMDIkSNx/fp1fPHFF+jcubPOe/aoF198EREREQCAI0eO4PPPP9fZrtVq0adPH+zbtw+jR49GUFAQTp06hQULFuDPP//Ejz/+aLC+ZX1e8vLy0KVLF/z111948803Ua9ePRw4cACxsbHIyMjAwoULDe6zovbu3Yuff/5Zb31WVhY6dOgAhUKBcePGoU6dOvjll18QFRUFjUaDCRMmGHW8cePGwdXVFTNmzEBaWhqWLl2Ky5cvS2GtWFpaGt544w28+eabGDVqFBo3bmxwfzk5OejUqRPOnDmDESNGoE2bNrhx4wZ++uknXL16Fe7u7kafH6pkgshMPvzwQwFAXLhwQWd9ly5dRLNmzaTllJQUAUCMHDlSp9zkyZMFALFz505pnZ+fnwgPD69wXXbt2iUAiA0bNuhtc3JyEpGRkdLyhAkTBADx66+/Suvu3r0r/P39Rf369UVRUZHOPp966imh0WiksuvXrxcAxKJFi/Rec8uWLcVnn30mrf/3v/8tfHx8RKdOnXTeEyGEyMvL01kuKCgQzZs3Fy+88ILea/jXv/4lAIjLly/rHLNLly7Scnx8vAAgjhw5UtrbJIQQIjIyUjg5Oemt37BhgwAgdu3aJdXHw8NDNG/eXNy7d08qt3nzZgFATJs2TVrXtWtX0aJFC3H//n1pnVarFc8++6xo2LBhmfW5ePGiACAcHBzE1atXpfWHDh0SAMTEiROldSXfMyGE+O677wQAsXfvXmldRESEsLGxMfheaLVaIUTp79f169cFADF9+nRp3fTp0wUA0adPH52y//jHPwQAceLECSGEEJcuXRJKpVLMmTNHp9ypU6dEjRo19NYXFBQIAGLcuHHSupLnQYiHnyMbGxudz6wQQixbtkwAEPv379dZX57Py+zZs4WTk5P4888/dZ777rvvCqVSKdLT04UQ/zs/n376qSipWbNmOvss/s48Wvf27duLnj176r2nUVFRwtvbW9y4cUNnnwMHDhQuLi4Gz3VZis9ncHCwKCgokNbPnTtXABD/93//J63z8/MTAMTWrVv19uPn56fz/8W0adMEALFp0ya9ssWfpYqeHzIP3jIjsym+DF27du0yyxX/dThp0iSd9cVXgUreqnoSd+/exY0bN3QehurTrl07dOzYUVrn7OyM0aNH49KlSzh9+rRO+YiICNSsWVNafvXVV+Ht7W3wr97hw4cjPj5eWo6Pj0dkZKTBRpqPXl26desW7ty5g06dOuG3337TK1t8Na487Rvu3LmDGzdu4O7du2WWK/k+lSx/9OhRZGdn4x//+IfOFa7w8HA0adJEOm83b97Ezp07MWDAAJ33/++//0ZYWBjOnj1r8BZbSX379sVTTz0lLbdr1w7t27fXeZ8ffc/u37+PGzduoEOHDgAgvW9arRY//vgjevfujbZt2+od59GrBBUVHR2ts/zWW28B+N9nfNOmTdBqtRgwYIDOe+vl5YWGDRti165dOs8vvt1m6AriozZs2ICgoCA0adJEZ78vvPACAOjttzyflw0bNqBTp06oVauWzj67deuGoqIi7N27V6d8Xl6e3memqKiozHpv2rQJR44cwccff6yzXgiB77//Hr1794YQQmefYWFhuHPnjsHvQXmMHj0atra20vLYsWNRo0YNve+rv78/wsLCHru/77//Hq1atTJ4lbP4s1TR80PmwVtmZDaXL1+Go6Mj1Gr1Y8vZ2Njo3fby8vKCq6srLl++XO5jXr9+Xec/YWdnZ532MCNGjChXvdu3b6+3PigoSNr+aHufhg0b6pRTKBQIDAzEpUuX9PYxePBgTJkyBYcPH4aHhwd2796Nr776Cvv27dMru3nzZnz44YdISUnRaWdg6Af79u3bAGCw7U9J3bp1k/7t6uqKN954A59++imcnJyk9bm5uahTp06Z+yk+L4ZuJTRp0kR6TefOnYMQAh988AE++OADg/vKzs7WCTuGlHyfAaBRo0ZYv369tHzz5k3MnDkTa9euRXZ2tk7ZO3fuAHj4GdFoNJUy9EPJOgYEBMDGxkb6LJw9exZCCIOvBYDODzUAKbC7uLiUedyzZ8/izJkzpZ6zku9FeT4vZ8+excmTJ8u9z+nTp2P69Ol65YpvZ5ZUVFSEf/7znxg8eDBatmyps+369eu4ffs2li9fjuXLl5fr+OVV8r13dnaGt7e33vf10dukZTl//jz69+9fZpmKnh8yDwYiMpu0tLRS77sb8iR/mRd75plndALU9OnTdRpqTps2DZ06ddJ5Tu/evZ/4uOVVp04d9O7dG/Hx8fD09MRzzz1nsP3Tr7/+ij59+qBz585YsmQJvL29YWtri/j4eKxZs0avfGZmJpydnXVCTWkWL16MRo0aIT8/H7t375Yawy5ZskQqY29vj//85z96dZo1a1ZFX7LUAHfy5Mml/sVtqjZgAwYMwIEDBxATE4PWrVvD2dkZWq0WPXr00GkIbC4lP9NarRYKhQK//PKLwc4GJQNK8Y90/fr1yzyOVqtFixYtMH/+fIPbfX19dZbL83nRarV48cUXMWXKFIPbGzVqpLM8evRovPbaazrrRo0aVer+V6xYgUuXLmHbtm0Gjw0AQ4YMQWRkpMHnlwxRpvbo1cYnVdHzQ+bBQERmcePGDaSmpmLMmDGPLevn5wetVouzZ89KV2GAh40qb9++DT8/v3Ifd/Xq1bh375603KBBA53tLVq00LlCAuj3gvPz80NaWprevv/44w9p+6POnj2rsyyEwLlz50r9D3vEiBEYPHgwXFxcSh2A7fvvv4e9vT22bdumc1vj0dttjzp9+rTOe1eWdu3aSbeKwsPDceLECWzdulWnjFKp1Hufiq8qFCt+H9LS0qRL/8XS0tKk7cXnwNbWVm+fFVHyfQaAP//8UwoLt27dQlJSEmbOnIlp06aV+rw6depArVbr9VAzhbNnz+pcWTh37hy0Wq1Ux4CAAAgh4O/vrxcoDCnuEWjo1t6jAgICcOLECXTt2rVcf1iU5/MSEBCAnJyccp+zhg0b6pUtLXDl5eVh5syZ+Mc//mHw+12nTh3UrFkTRUVFT/SZMeTs2bN4/vnnpeWcnBxkZGSgV69eRu0vICDgsZ+lip4fMg+2IaJKp9VqMWXKFKmtxOMU/0dUstdK8V9TpfWoMuS5555Dt27dpEfJQFQevXr1wuHDh5GcnCyty83NxfLly1G/fn00bdpUp3xx76diGzduREZGBnr27Glw/z169ICTkxNu3rxZ6vujVCqhUCh0bv9dunTJYG+UK1euYP/+/XqhpLy0Wm25hkYoqW3btvDw8MCyZct0bun98ssvOHPmjHTePDw8EBoaiq+++goZGRl6+7l+/Xq5jvfjjz/qtDU6fPgwDh06JL3Pxa9B/Hf8q2IlP1c2Njbo27cv/vOf/xgcgqDk8yti8eLFOstffPEFAEh17NevH5RKJWbOnKl3HCGE3vAAGzduROPGjdGkSZMyjztgwAD89ddf+Ne//qW37d69e8jNzZWWy/t5GTBgAJKTkw1ewbl9+zYePHhQ5vPLsmjRIuTm5uK9994zuF2pVKJ///74/vvvDYaN8n5mDFm+fLk0JAgALF26FA8ePCj1+/o4/fv3x4kTJ/R6wwL/+yxV5PyQ+fAKEVWqI0eOICoqCqdOncKoUaPQpUuXxz6nVatWiIyMxPLly3H79m106dIFhw8fxsqVK9G3b1+dv+bM4d1338V3332Hnj174u2334abmxtWrlyJixcv4vvvv9drAO3m5oaOHTti+PDhyMrKwsKFCxEYGFjq7QKlUokzZ85ACFHqX9Dh4eGYP38+evTogUGDBiE7OxuLFy9GYGAgTp48KZVbunQp4uLi4OjoiLfffrtcry85ORk3btyQbpklJSVh8uTJ5Xx3/sfW1haffPIJhg8fji5duuCNN96Qut3Xr18fEydOlMouXrwYHTt2RIsWLTBq1Cg0aNAAWVlZSE5OxtWrV3HixInHHi8wMBAdO3bE2LFjkZ+fj4ULF6J27drSLR21Wo3OnTtj7ty5KCwsxFNPPYXt27fj4sWLevv66KOPsH37dnTp0kXqBp2RkYENGzZg3759Bru+l8fFixfRp08f9OjRA8nJyVi1ahUGDRqEVq1aAXh4peDDDz9EbGwsLl26hL59+6JmzZq4ePEifvjhB4wePRqTJ0/GhQsXMHfuXBw+fBj9+vXDqlWrpGMcOXIEwMMhBurVq4cGDRpg6NChWL9+PcaMGYNdu3bhueeeQ1FREf744w+sX79eGk+nIp+XmJgY/PTTT3jppZcwbNgwBAcHIzc3F6dOncLGjRtx6dIlqct+RW3fvh1z5swps8PFxx9/jF27dqF9+/YYNWoUmjZtips3b+K3337Djh07cPPmTaOOXVBQgK5du2LAgAFIS0vDkiVL0LFjR/Tp08eo/cXExGDjxo147bXXMGLECAQHB+PmzZv46aefsGzZMrRq1arc54fMzDKd20guVq1aJZ599lmxcuVKqctpSSW73QshRGFhoZg5c6bw9/cXtra2wtfXV8TGxup00xbCPN3uhRDi/Pnz4tVXXxWurq7C3t5etGvXTmzevNngPr/77jsRGxsrPDw8hIODgwgPD9fpzlzaa37c9hUrVoiGDRsKlUolmjRpIuLj46Xu3cXatWsnXnvtNfHHH38Y3KehbvfFDzs7OxEYGCimTZsm8vPzpXLl7XZfbN26deLpp58WKpVKuLm5icGDB+t0jy92/vx5ERERIby8vIStra146qmnxEsvvSQ2btxY6vsihG637nnz5glfX1+hUqlEp06dpO7sxa5evSpeeeUV4erqKlxcXMRrr70mrl27ptelWwghLl++LCIiIkSdOnWESqUSDRo0ENHR0dJ7YUy3+9OnT4tXX31V1KxZU9SqVUuMGzdOZ0iCYt9//73o2LGjcHJyEk5OTqJJkyYiOjpapKWl6Rz7cY/4+HhpnwUFBeKTTz4RzZo1EyqVStSqVUsEBweLmTNnijt37gghKvZ5EeLhcBOxsbEiMDBQ2NnZCXd3d/Hss8+Kzz77TOq6bky3e29vb5Gbm6tT1tA5ysrKEtHR0cLX11fY2toKLy8v0bVrV7F8+XK9Yz1O8Xu6Z88eMXr0aFGrVi3h7OwsBg8eLP7++2+dsmX9P1Oy270QQvz9999i3Lhx4qmnnhJ2dnbCx8dHREZG6gwZUJ7zQ+bFQERkImWFLDKdsn5wrUVxILp+/bpJ9hcfHy/8/PzKLNOlSxedQERlK+84XCQfbENEREREssdARERk5QICAh47ncmLL76IgIAAM9WIqPpho2oiIivXqVMnvfGySiqthxYRlY9CiCfoU0pERERUDfCWGREREckeAxERERHJHtsQlYNWq8W1a9dQs2ZNDrNORERURQghcPfuXdStW1dvEN2SGIjK4dq1a5xsj4iIqIq6cuUKfHx8yizDQFQONWvWBPDwDVWr1RauDREREZWHRqOBr6+v9DteFgaicii+TaZWqxmIiIiIqpjyNHdho2oiIiKSPQYiIiIikj0GIiIiIpI9tiEiIiKyACEEHjx4gKKiIktXpUqztbWFUql84v0wEBEREZlZQUEBMjIykJeXZ+mqVHkKhQI+Pj5wdnZ+ov0wEBEREZmRVqvFxYsXoVQqUbduXdjZ2XHQXyMJIXD9+nVcvXoVDRs2fKIrRQxEREREZlRQUACtVgtfX184OjpaujpVXp06dXDp0iUUFhY+USBio2oiIiILeNxUElQ+prq6xrNBREREssdbZkRERFYhHcANMx7PHUA9Mx7PujEQERERWVw6irRBUNqYr9dZkdYRSpszqOxQdOnSJfj7++P48eNo3bp1pR7rSTAQERERWdwNKG3yMH7tOziX7VvpRwv0uIJFA+fh4RWpyg1Evr6+yMjIgLu7e6Ue50kxEBEREVmJc9m+SL0WaOlqmExBQQHs7Ozg5eVl6ao8FhtVE1WKdAC/GXikW7JSRERPJDQ0FOPGjcO4cePg4uICd3d3fPDBBxBCAADq16+P2bNnIyIiAmq1GqNHj8alS5egUCiQkpIi7Sc1NRUvvfQS1Go1atasiU6dOuH8+fPS9q+//hpBQUGwt7dHkyZNsGTJkkp/bbxCRGRypbcFMNc9eyKiyrJy5UpERUXh8OHDOHr0KEaPHo169eph1KhRAIDPPvsM06ZNw/Tp0w0+/6+//kLnzp0RGhqKnTt3Qq1WY//+/Xjw4AEAYPXq1Zg2bRq+/PJLPP300zh+/DhGjRoFJycnREZGVtrrYiAiMjnDbQHMec+eiKiy+Pr6YsGCBVAoFGjcuDFOnTqFBQsWSIHohRdewDvvvCOVv3Tpks7zFy9eDBcXF6xduxa2trYAgEaNGknbp0+fjnnz5qFfv34AAH9/f5w+fRpfffUVAxFRVVTd2gIQEQFAhw4ddAZDDAkJwbx586RJatu2bVvm81NSUtCpUycpDD0qNzcX58+fR1RUlBSwAODBgwdwcXEx0SswjIGIiIiITMbJyanM7Q4ODqVuy8nJAQD861//Qvv27XW2mWJG+7IwEBEREVG5HTp0SGf54MGDFZpYtWXLlli5ciUKCwv1rhJ5enqibt26uHDhAgYPHmyyOpcHAxEREZGVCPS4YvXHSU9Px6RJk/Dmm2/it99+wxdffIF58+aV+/njxo3DF198gYEDByI2NhYuLi44ePAg2rVrh8aNG2PmzJl4++234eLigh49eiA/Px9Hjx7FrVu3MGnSJKPr/TgMRERERBbnjiKt4387XpjHw16vFR8sMSIiAvfu3UO7du2gVCoxfvx4jB49utzPr127Nnbu3ImYmBh06dIFSqUSrVu3xnPPPQcAGDlyJBwdHfHpp58iJiYGTk5OaNGiBSZMmFDhulYEAxEREZHF1fvvkBzmm8vsYRiqeI9XW1tbLFy4EEuXLtXbVrJHGfBwbKLicYqKtWzZEtu2bSv1GIMGDcKgQYMqXLcnwUBERERkFeqBQ3JYDkeqJiIiItnjFSIiIiIql927d1u6CpWGV4iIiIhI9hiIiIiILKBkQ2MyjqneRwYiIiIiMyoejDAvT38CaKq4goICAE8+kjXbEBEREZmRUqmEq6srsrOzAQCOjo46c4NR+Wm1Wly/fh2Ojo6oUePJIg0DERERkZl5eXkBgBSKyHg2NjaoV6/eE4dKBiIiIiIzUygU8Pb2hoeHBwoLCy1dnSrNzs4ONjZP3gKIgYiIiMhClEplpc/iTuXDRtVEREQkewxEREREJHsMRERERCR7Fg1ES5cuRcuWLaFWq6FWqxESEoJffvlF2h4aGgqFQqHzGDNmjM4+0tPTER4eDkdHR3h4eCAmJgYPHjzQKbN79260adMGKpUKgYGBSEhIMMfLIyIioirCoo2qfXx88PHHH6Nhw4YQQmDlypV4+eWXcfz4cTRr1gwAMGrUKMyaNUt6jqOjo/TvoqIihIeHw8vLCwcOHEBGRgYiIiJga2uLjz76CABw8eJFhIeHY8yYMVi9ejWSkpIwcuRIeHt7IywszLwvmIiIiKySRQNR7969dZbnzJmDpUuX4uDBg1IgcnR0lMZrKGn79u04ffo0duzYAU9PT7Ru3RqzZ8/G1KlTMWPGDNjZ2WHZsmXw9/fHvHnzAABBQUHYt28fFixYUGogys/PR35+vrSs0WhM8XKJiIjISllNG6KioiKsXbsWubm5CAkJkdavXr0a7u7uaN68OWJjY3WGOk9OTkaLFi3g6ekprQsLC4NGo0FqaqpUplu3bjrHCgsLQ3Jycql1iYuLg4uLi/Tw9fU11cskIiIiK2TxcYhOnTqFkJAQ3L9/H87Ozvjhhx/QtGlTAMCgQYPg5+eHunXr4uTJk5g6dSrS0tKwadMmAEBmZqZOGAIgLWdmZpZZRqPR4N69e3BwcNCrU2xsLCZNmiQtazQahiIiIqJqzOKBqHHjxkhJScGdO3ewceNGREZGYs+ePWjatClGjx4tlWvRogW8vb3RtWtXnD9/HgEBAZVWJ5VKBZVKVWn7JyIiIuti8VtmdnZ2CAwMRHBwMOLi4tCqVSssWrTIYNn27dsDAM6dOwfg4VwwWVlZOmWKl4vbHZVWRq1WG7w6RERERPJj8UBUklar1WnQ/KiUlBQAgLe3NwAgJCQEp06d0pkcLzExEWq1WrrtFhISgqSkJJ39JCYm6rRTIiIiInmz6C2z2NhY9OzZE/Xq1cPdu3exZs0a7N69G9u2bcP58+exZs0a9OrVC7Vr18bJkycxceJEdO7cGS1btgQAdO/eHU2bNsXQoUMxd+5cZGZm4v3330d0dLR0y2vMmDH48ssvMWXKFIwYMQI7d+7E+vXrsWXLFku+dCIiIrIiFg1E2dnZiIiIQEZGBlxcXNCyZUts27YNL774Iq5cuYIdO3Zg4cKFyM3Nha+vL/r374/3339fer5SqcTmzZsxduxYhISEwMnJCZGRkTrjFvn7+2PLli2YOHEiFi1aBB8fH3z99dccg4iIiIgkFg1EK1asKHWbr68v9uzZ89h9+Pn54eeffy6zTGhoKI4fP17h+hEREZE8WF0bIiIiIiJzYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZs/jkrkRkLukAbpSyzR1APTPWhYjIujAQEclCOoq0QVDa5BncWqR1hNLmDBiKiEiuGIiIZOEGlDZ5GL/2HZzL9tXZEuhxBYsGzsPDq0cMREQkTwxERDJyLtsXqdcCLV0NIiKrw0bVREREJHsMRERERCR7DEREREQke2xDRDJVWhd0dj8vH75/RFS9MBCRDJXeBb307ucMAP9jzPtHRGTdGIhIhgx3QS+9+zkDgK6Kvn9ERNaPgYhkq/xd0K01AFj2qhW78BNRdcJARFRO1hUAeNWKiMiUGIiIqiRrvWpFRFQ1MRARVWHWddWKiKjq4jhEREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7DEREREQke+x2T2Q1OF8aEZGlMBARWQWOPE1EZEkMRERP7MxjlsuDI08TEVkSAxGRkeo430KRVgGlzRCT7ZMjTxMRWQYDEZGR1A45UNoIvas6oY2PIiZslQVrRkREFcVARPSESl7VCahzpRKOYorbckREVBoGIiIrVhm35YiISB8DEZEVM+9tOUNXndjln4jkwaIDMy5duhQtW7aEWq2GWq1GSEgIfvnlF2n7/fv3ER0djdq1a8PZ2Rn9+/dHVlaWzj7S09MRHh4OR0dHeHh4ICYmBg8ePNAps3v3brRp0wYqlQqBgYFISEgwx8sjMpni23LFjys3PU227+KrUMAQAME6jyJtEB6Oj0REVL1Z9AqRj48PPv74YzRs2BBCCKxcuRIvv/wyjh8/jmbNmmHixInYsmULNmzYABcXF4wbNw79+vXD/v37AQBFRUUIDw+Hl5cXDhw4gIyMDERERMDW1hYfffQRAODixYsIDw/HmDFjsHr1aiQlJWHkyJHw9vZGWFiYJV8+kVUo7SoUu/wTkZxYNBD17t1bZ3nOnDlYunQpDh48CB8fH6xYsQJr1qzBCy+8AACIj49HUFAQDh48iA4dOmD79u04ffo0duzYAU9PT7Ru3RqzZ8/G1KlTMWPGDNjZ2WHZsmXw9/fHvHnzAABBQUHYt28fFixYwEBE9Ah2+SciObOaucyKioqwdu1a5ObmIiQkBMeOHUNhYSG6desmlWnSpAnq1auH5ORkAEBycjJatGgBT8//3T4ICwuDRqNBamqqVObRfRSXKd6HIfn5+dBoNDoPIiIiqr4sHohOnToFZ2dnqFQqjBkzBj/88AOaNm2KzMxM2NnZwdXVVae8p6cnMjMzAQCZmZk6Yah4e/G2sspoNBrcu3fPYJ3i4uLg4uIiPXx9fQ2WIyIiourB4oGocePGSElJwaFDhzB27FhERkbi9OnTFq1TbGws7ty5Iz2uXKmMcWWIiIjIWli8272dnR0CAx+2WwgODsaRI0ewaNEivP766ygoKMDt27d1rhJlZWXBy8sLAODl5YXDhw/r7K+4F9qjZUr2TMvKyoJarYaDg4PBOqlUKqhUKpO8PiIiIrJ+Fr9CVJJWq0V+fj6Cg4Nha2uLpKQkaVtaWhrS09MREhICAAgJCcGpU6eQnZ0tlUlMTIRarUbTpk2lMo/uo7hM8T6IiIiILHqFKDY2Fj179kS9evVw9+5drFmzBrt378a2bdvg4uKCqKgoTJo0CW5ublCr1XjrrbcQEhKCDh06AAC6d++Opk2bYujQoZg7dy4yMzPx/vvvIzo6WrrCM2bMGHz55ZeYMmUKRowYgZ07d2L9+vXYsmWLJV86ERERWRGLBqLs7GxEREQgIyMDLi4uaNmyJbZt24YXX3wRALBgwQLY2Nigf//+yM/PR1hYGJYsWSI9X6lUYvPmzRg7dixCQkLg5OSEyMhIzJo1Syrj7++PLVu2YOLEiVi0aBF8fHzw9ddfs8s9ERERSSwaiFasWFHmdnt7eyxevBiLFy8utYyfnx9+/vnnMvcTGhqK48ePG1VHIiIiqv6srg0RERERkbkxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkexZfC4zIrJ2Zx6zTERU9TEQEZFBdZxvoUirgNJmiKWrQkRU6RiIiMggtUMOlDYC49e+g3PZvtL60MZHERO2yoI1IyIyPQYiIirTuWxfpF4LlJYD6lyxYG2IiCoHG1UTERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7Fk0EMXFxeGZZ55BzZo14eHhgb59+yItLU2nTGhoKBQKhc5jzJgxOmXS09MRHh4OR0dHeHh4ICYmBg8ePNAps3v3brRp0wYqlQqBgYFISEio7JdHREREVYRFA9GePXsQHR2NgwcPIjExEYWFhejevTtyc3N1yo0aNQoZGRnSY+7cudK2oqIihIeHo6CgAAcOHMDKlSuRkJCAadOmSWUuXryI8PBwPP/880hJScGECRMwcuRIbNu2zWyvlYiIiKxXDUsefOvWrTrLCQkJ8PDwwLFjx9C5c2dpvaOjI7y8vAzuY/v27Th9+jR27NgBT09PtG7dGrNnz8bUqVMxY8YM2NnZYdmyZfD398e8efMAAEFBQdi3bx8WLFiAsLCwynuBREREVCVYVRuiO3fuAADc3Nx01q9evRru7u5o3rw5YmNjkZeXJ21LTk5GixYt4OnpKa0LCwuDRqNBamqqVKZbt246+wwLC0NycrLBeuTn50Oj0eg8iIiIqPqy6BWiR2m1WkyYMAHPPfccmjdvLq0fNGgQ/Pz8ULduXZw8eRJTp05FWloaNm3aBADIzMzUCUMApOXMzMwyy2g0Gty7dw8ODg462+Li4jBz5kyTv0YiIiKyTlYTiKKjo/H7779j3759OutHjx4t/btFixbw9vZG165dcf78eQQEBFRKXWJjYzFp0iRpWaPRwNfXt1KORURERJZnFbfMxo0bh82bN2PXrl3w8fEps2z79u0BAOfOnQMAeHl5ISsrS6dM8XJxu6PSyqjVar2rQwCgUqmgVqt1HkRERFR9WTQQCSEwbtw4/PDDD9i5cyf8/f0f+5yUlBQAgLe3NwAgJCQEp06dQnZ2tlQmMTERarUaTZs2lcokJSXp7CcxMREhISEmeiVERERUlVk0EEVHR2PVqlVYs2YNatasiczMTGRmZuLevXsAgPPnz2P27Nk4duwYLl26hJ9++gkRERHo3LkzWrZsCQDo3r07mjZtiqFDh+LEiRPYtm0b3n//fURHR0OlUgEAxowZgwsXLmDKlCn4448/sGTJEqxfvx4TJ0602GsnIiIi62HRQLR06VLcuXMHoaGh8Pb2lh7r1q0DANjZ2WHHjh3o3r07mjRpgnfeeQf9+/fHf/7zH2kfSqUSmzdvhlKpREhICIYMGYKIiAjMmjVLKuPv748tW7YgMTERrVq1wrx58/D111+zyz0REREBsHCjaiFEmdt9fX2xZ8+ex+7Hz88PP//8c5llQkNDcfz48QrVj4iMccbAOncA9cxdESKicrOaXmZEVLXVcb6FIq0CSpshetuKtI5Q2pwBQxERWSsGIiIyCbVDDpQ2AuPXvoNz2f8bpiLQ4woWDZwH4AYYiIjIWjEQEZFJncv2Req1QEtXg4ioQhiIiKqlku14DLXrISKiYgxERNVIWe14iIiodAxERNVIae14QhsfRUzYKgvWjIjIujEQEVVDJdvxBNS5YsHaEBFZP6uYy4yIiIjIkhiIiIiISPYYiIiIiEj2jGpDdOHCBTRo0MDUdSEi2UnHwwEbDeF0H0RkPkYFosDAQHTp0gVRUVF49dVXYW9vb+p6EVG1U3IspAwUaV+D0uaewdKc7oOIzMmoQPTbb78hPj4ekyZNwrhx4/D6668jKioK7dq1M3X9iKiKK2tsJKUN9IYIADjdBxGZn1GBqHXr1li0aBHmzZuHn376CQkJCejYsSMaNWqEESNGYOjQoahTp46p60pEVdDjxkbiVB9EZA2eqFF1jRo10K9fP2zYsAGffPIJzp07h8mTJ8PX1xcRERHIyMgwVT2JqIorDj7Fjys3PS1dJSIiyRMFoqNHj+If//gHvL29MX/+fEyePBnnz59HYmIirl27hpdfftlU9SQiIiKqNEbdMps/fz7i4+ORlpaGXr164dtvv0WvXr1gY/MwX/n7+yMhIQH169c3ZV2JiMyAPd+I5MioQLR06VKMGDECw4YNg7e3t8EyHh4eWLFixRNVjojIvNJRpA2C0ibP4Fb2fCOqvowKRGfPnn1sGTs7O0RGRhqzeyIiC7kBpU0ee74RyZBRgSg+Ph7Ozs547bXXdNZv2LABeXl5DEJEVKWx5xuR/BjVqDouLg7u7u566z08PPDRRx89caWIiIiIzMmoQJSeng5/f3+99X5+fkhPT3/iShERERGZk1GByMPDAydPntRbf+LECdSuXfuJK0VERERkTka1IXrjjTfw9ttvo2bNmujcuTMAYM+ePRg/fjwGDhxo0goSPV5p3aTZRZqIiMrHqEA0e/ZsXLp0CV27dkWNGg93odVqERERwTZEZGald5NmF2kiIiovowKRnZ0d1q1bh9mzZ+PEiRNwcHBAixYt4OfnZ+r6ET2G4W7S7CJNREQVYVQgKtaoUSM0atTIVHUhMhq7ScsJb5ESkekZFYiKioqQkJCApKQkZGdnQ6vV6mzfuXOnSSpHRKSLt0iJqHIYFYjGjx+PhIQEhIeHo3nz5lAoFKauFxGRAVXtFimvZhFVFUYForVr12L9+vXo1auXqetDZGJnyrmOqpKqcYuUV7OIqhKjG1UHBlr7f0YkZ3Wcb6FIq4DSZoilq0KyVdWuZhHJm1GB6J133sGiRYvw5Zdf8nYZWSW1Qw6UNsLgJJ2hjY8iJmyVhWpGclM1rmYRkVGBaN++fdi1axd++eUXNGvWDLa2tjrbN23aZJLKET0pQz9GAXWuWKg2RERkrYwKRK6urnjllVdMXRciIiIiizAqEMXHx5u6HkREREQWY9TkrgDw4MED7NixA1999RXu3r0LALh27RpycnJMVjkiIiIiczAqEF2+fBktWrTAyy+/jOjoaFy/fh0A8Mknn2Dy5Mnl3k9cXByeeeYZ1KxZEx4eHujbty/S0tJ0yty/fx/R0dGoXbs2nJ2d0b9/f2RlZemUSU9PR3h4OBwdHeHh4YGYmBg8ePBAp8zu3bvRpk0bqFQqBAYGIiEhwZiXTkRERNWQUYFo/PjxaNu2LW7dugUHBwdp/SuvvIKkpKRy72fPnj2Ijo7GwYMHkZiYiMLCQnTv3h25ublSmYkTJ+I///kPNmzYgD179uDatWvo16+ftL2oqAjh4eEoKCjAgQMHsHLlSiQkJGDatGlSmYsXLyI8PBzPP/88UlJSMGHCBIwcORLbtm0z5uUTERFRNWNUG6Jff/0VBw4cgJ2dnc76+vXr46+//ir3frZu3aqznJCQAA8PDxw7dgydO3fGnTt3sGLFCqxZswYvvPACgIftl4KCgnDw4EF06NAB27dvx+nTp7Fjxw54enqidevWmD17NqZOnYoZM2bAzs4Oy5Ytg7+/P+bNmwcACAoKwr59+7BgwQKEhYUZ8xYQERFRNWLUFSKtVouioiK99VevXkXNmjWNrsydO3cAAG5ubgCAY8eOobCwEN26dZPKNGnSBPXq1UNycjIAIDk5GS1atICnp6dUJiwsDBqNBqmpqVKZR/dRXKZ4HyXl5+dDo9HoPIiIiKj6MioQde/eHQsXLpSWFQoFcnJyMH36dKOn89BqtZgwYQKee+45NG/eHACQmZkJOzs7uLq66pT19PREZmamVObRMFS8vXhbWWU0Gg3u3bunV5e4uDi4uLhID19fX70yVFI6gN9KeaRbsF5ERESPZ9Qts3nz5iEsLAxNmzbF/fv3MWjQIJw9exbu7u747rvvjKpIdHQ0fv/9d+zbt8+o55tSbGwsJk2aJC1rNBqGojKVPmcTwHmbiIjI+hkViHx8fHDixAmsXbsWJ0+eRE5ODqKiojB48GCdRtblNW7cOGzevBl79+6Fj4+PtN7LywsFBQW4ffu2zlWirKwseHl5SWUOHz6ss7/iXmiPlinZMy0rKwtqtdpgfVUqFVQqVYVfh3wZnrMJ4LxNRERUNRgViACgRo0aGDLkySbOFELgrbfewg8//IDdu3fD399fZ3twcDBsbW2RlJSE/v37AwDS0tKQnp6OkJAQAEBISAjmzJmD7OxseHh4AAASExOhVqvRtGlTqczPP/+ss+/ExERpH2QanLOJiIiqKqMC0bffflvm9oiIiHLtJzo6GmvWrMH//d//oWbNmlKbHxcXFzg4OMDFxQVRUVGYNGkS3NzcoFar8dZbbyEkJAQdOnQA8LA9U9OmTTF06FDMnTsXmZmZeP/99xEdHS1d5RkzZgy+/PJLTJkyBSNGjMDOnTuxfv16bNmyxZiXT0RERNWMUYFo/PjxOsuFhYXIy8uDnZ0dHB0dyx2Ili5dCgAIDQ3VWR8fH49hw4YBABYsWAAbGxv0798f+fn5CAsLw5IlS6SySqUSmzdvxtixYxESEgInJydERkZi1qxZUhl/f39s2bIFEydOxKJFi+Dj44Ovv/6aXe6JiIgIgJGB6NatW3rrzp49i7FjxyImJqbc+xFCPLaMvb09Fi9ejMWLF5daxs/PT++WWEmhoaE4fvx4uetGRERE8mH0XGYlNWzYEB9//LHe1SMiIiIia2eyQAQ8bGh97do1U+6SiIiIqNIZdcvsp59+0lkWQiAjIwNffvklnnvuOZNUjIiIiMhcjApEffv21VlWKBSoU6cOXnjhBWm+MCIiIqKqwqhApNVqTV0PIiIiIosxemBGIiLrc8bAOndwlHQiehyjAtGj83w9zvz58405BBFRudVxvoUirQJKG/3R8zmXHhGVh1GB6Pjx4zh+/DgKCwvRuHFjAMCff/4JpVKJNm3aSOUUCoVpaklEVAa1Qw6UNkJvPj3OpUdE5WVUIOrduzdq1qyJlStXolatWgAeDtY4fPhwdOrUCe+8845JK0lEVB6cT4+IjGXUOETz5s1DXFycFIYAoFatWvjwww/Zy4yIiIiqHKMCkUajwfXr1/XWX79+HXfv3n3iShERERGZk1GB6JVXXsHw4cOxadMmXL16FVevXsX333+PqKgo9OvXz9R1JCIiIqpURrUhWrZsGSZPnoxBgwahsLDw4Y5q1EBUVBQ+/fRTk1aQiIiIqLIZFYgcHR2xZMkSfPrppzh//jwAICAgAE5OTiatHFUnHB+GiIis1xMNzJiRkYGMjAx07twZDg4OEEKwqz3p4PgwRERUFRgViP7++28MGDAAu3btgkKhwNmzZ9GgQQNERUWhVq1a7GlGEo4PQ0REVYFRjaonTpwIW1tbpKenw9HRUVr/+uuvY+vWrSarHFUfxePDFD8eDUdERESWZtQVou3bt2Pbtm3w8fHRWd+wYUNcvnzZJBUjqr4MtacytI6IiMzFqECUm5urc2Wo2M2bN6FSqZ64UkTVUVntqYiIyLKMCkSdOnXCt99+i9mzZwN4OGeZVqvF3Llz8fzzz5u0gkTVRWntqQAgtPFRxIStslDNiIjIqEA0d+5cdO3aFUePHkVBQQGmTJmC1NRU3Lx5E/v37zd1HYmqFUPzbQXUuWKh2hAREWBkIGrevDn+/PNPfPnll6hZsyZycnLQr18/REdHw9vb29R1JNlJx8PeZyVx3CIiIqocFQ5EhYWF6NGjB5YtW4b33nuvMupEspaOIm0QlDZ5els4bhEREVWWCgciW1tbnDx5sjLqQgTgBpQ2eRy3iIiIzMqocYiGDBmCFStWmLouRBKOW0REROZkVBuiBw8e4JtvvsGOHTsQHBysN4fZ/PnzTVI5IiIiInOoUCC6cOEC6tevj99//x1t2rQBAPz55586ZTiXGREREVU1FQpEDRs2REZGBnbt2gXg4VQdn3/+OTw9PSulckRERETmUKE2REIIneVffvkFubm5Jq0QERERkbkZ1YaoWMmARERkWiXneOOcb0RUOSoUiBQKhV4bIbYZIiJT47xvRGRuFQpEQggMGzZMmsD1/v37GDNmjF4vs02bNpmuhkQkO6XN+8Y534ioslQoEEVGRuosDxnCv96IqPKUnPeNc74RUWWpUCCKj4+vrHoQERERWYxRI1UTERERVScMRERERCR7Fg1Ee/fuRe/evVG3bl0oFAr8+OOPOtuHDRsm9WwrfvTo0UOnzM2bNzF48GCo1Wq4uroiKioKOTk5OmVOnjyJTp06wd7eHr6+vpg7d25lvzQiIiKqQiwaiHJzc9GqVSssXry41DI9evRARkaG9Pjuu+90tg8ePBipqalITEzE5s2bsXfvXowePVrartFo0L17d/j5+eHYsWP49NNPMWPGDCxfvrzSXhcRERFVLU80MOOT6tmzJ3r27FlmGZVKBS8vL4Pbzpw5g61bt+LIkSNo27YtAOCLL75Ar1698Nlnn6Fu3bpYvXo1CgoK8M0338DOzg7NmjVDSkoK5s+frxOciIiISL6svg3R7t274eHhgcaNG2Ps2LH4+++/pW3JyclwdXWVwhAAdOvWDTY2Njh06JBUpnPnzrCzs5PKhIWFIS0tDbdu3TJ4zPz8fGg0Gp0HERERVV9WHYh69OiBb7/9FklJSfjkk0+wZ88e9OzZE0VFRQCAzMxMeHh46DynRo0acHNzQ2ZmplSm5OSzxcvFZUqKi4uDi4uL9PD19TVYjoiIiKoHi94ye5yBAwdK/27RogVatmyJgIAA7N69G127dq2048bGxmLSpEnSskajYSgiIgtLB3DDwHp3APXMXBei6seqA1FJDRo0gLu7O86dO4euXbvCy8sL2dnZOmUePHiAmzdvSu2OvLy8kJWVpVOmeLm0tkkqlUqanoSIyPLSUaQNgtImT29LkdYRSpszYCgiejJVKhBdvXoVf//9N7y9vQEAISEhuH37No4dO4bg4GAAwM6dO6HVatG+fXupzHvvvYfCwkLY2toCABITE9G4cWPUqlXLMi+EiKhCbkBpk6c3t1ugxxUsGjgPD68cMRARPQmLtiHKyclBSkoKUlJSAAAXL15ESkoK0tPTkZOTg5iYGBw8eBCXLl1CUlISXn75ZQQGBiIsLAwAEBQUhB49emDUqFE4fPgw9u/fj3HjxmHgwIGoW7cuAGDQoEGws7NDVFQUUlNTsW7dOixatEjnlhgRUVVQPLdb8ePRcERET8aigejo0aN4+umn8fTTTwMAJk2ahKeffhrTpk2DUqnEyZMn0adPHzRq1AhRUVEIDg7Gr7/+qnM7a/Xq1WjSpAm6du2KXr16oWPHjjpjDLm4uGD79u24ePEigoOD8c4772DatGnsck9EREQSi94yCw0NhRCi1O3btm177D7c3NywZs2aMsu0bNkSv/76a4XrR0RU/bBxNpEhVaoNERERPQk2ziYqDQMREZFssHE2UWkYiIiIZKa4cTYR/Y9Vj1RNREREZA4MRERERCR7DEREREQkewxEREREJHsMRERERCR7DEREREQkewxEREREJHsch4iqmDOPWSYiIqo4BiKqEuo430KRVgGlzRBLV4WIiKohBiKqEtQOOVDaCL0pB0IbH0VM2CoL1oyIiKoDBiKqUkpOORBQ54oFa0NERNUFAxERyYChtmbu4ESmRFSMgYiIqq2y2p4VaR2htDkDhiIiAhiIiKgaK63tWaDHFSwaOA/ADTAQERHAQEREMlCy7RkRUUkcmJGIiIhkj1eIqILS8fA2w6M4OCIREVVtDERUAeko0gZBaZNn6YoQERGZFAMRVcANKG3yODgiERFVOwxEVGEcHJGqD86NR0QPMRAR6eGPZHXHufGIqCQGIqL/4o+kfHBuPCIqiYGI6L/4Iyk/vP1LRMUYiIhK4I8kEZH8cGBGIiIikj0GIiIiIpI9BiIiIiKSPbYhIiKyGoamxgE49ANR5WMgIiJ6YqaY449T4xBZEgMRlYKTuBKVj6mCjOGpcQAO/UBkDgxEZAD/UiUqP9PO8Vdy2AeAQz8QmQMDERnASVyJKorjVxFVbQxEVCr+B09ERHJh0W73e/fuRe/evVG3bl0oFAr8+OOPOtuFEJg2bRq8vb3h4OCAbt264ezZszplbt68icGDB0OtVsPV1RVRUVHIycnRKXPy5El06tQJ9vb28PX1xdy5cyv7pREREVEVYtFAlJubi1atWmHx4sUGt8+dOxeff/45li1bhkOHDsHJyQlhYWG4f/++VGbw4MFITU1FYmIiNm/ejL1792L06NHSdo1Gg+7du8PPzw/Hjh3Dp59+ihkzZmD58uWV/vqIiIioarDoLbOePXuiZ8+eBrcJIbBw4UK8//77ePnllwEA3377LTw9PfHjjz9i4MCBOHPmDLZu3YojR46gbdu2AIAvvvgCvXr1wmeffYa6deti9erVKCgowDfffAM7Ozs0a9YMKSkpmD9/vk5wIiIiIvmy2pGqL168iMzMTHTr1k1a5+Ligvbt2yM5ORkAkJycDFdXVykMAUC3bt1gY2ODQ4cOSWU6d+4MOzs7qUxYWBjS0tJw69Ytg8fOz8+HRqPReRAREVH1ZbWBKDMzEwDg6emps97T01PalpmZCQ8PD53tNWrUgJubm04ZQ/t49BglxcXFwcXFRXr4+voaLEdERETVg9UGIkuKjY3FnTt3pMeVK+xdRUREVJ1ZbSDy8vICAGRlZemsz8rKkrZ5eXkhOztbZ/uDBw9w8+ZNnTKG9vHoMUpSqVRQq9U6DyIiIqq+rDYQ+fv7w8vLC0lJSdI6jUaDQ4cOISQkBAAQEhKC27dv49ixY1KZnTt3QqvVon379lKZvXv3orCwUCqTmJiIxo0bo1atWmZ6NURERGTNLBqIcnJykJKSgpSUFAAPG1KnpKQgPT0dCoUCEyZMwIcffoiffvoJp06dQkREBOrWrYu+ffsCAIKCgtCjRw+MGjUKhw8fxv79+zFu3DgMHDgQdevWBQAMGjQIdnZ2iIqKQmpqKtatW4dFixZh0qRJFnrVREREZG0s2u3+6NGjeP7556Xl4pASGRmJhIQETJkyBbm5uRg9ejRu376Njh07YuvWrbC3t5ees3r1aowbNw5du3aFjY0N+vfvj88//1za7uLigu3btyM6OhrBwcFwd3fHtGnT2OWeiIxUcpJjTnpMVB1YNBCFhoZCCFHqdoVCgVmzZmHWrFmllnFzc8OaNWvKPE7Lli3x66+/Gl1PIqI6zrdQpFVAaTPE0lUhokrAucyIiMpB7ZADpY3gpMdE1RQDERFRBXDSY6LqyWp7mRERERGZCwMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeR6omIqqW0gHcKLHO1BPRGjoGALgDqGfiYxFVLgYiIqJqJx1F2iAobfIscowirSOUNmfAUERVCQMREVG1cwNKm7xKnojW8DECPa5g0cB5eHjliIGIqg4GIiKiasocE9GWPAZRVcVG1URERCR7vEIkG2z8SEREVBoGIllg40ciIqKyMBDJAhs/EpGxSru6bOou/ESWxUAkI2z8SEQVY47u+0TWgYGIiIhKYfjqMmDqLvxElsdAREREZTJ0dbkyuvATWRK73RMREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkeyx2z1Bf8RZc45Aa8ljE1kSP/tE1oSBSMbqON9CkVYBpc0QWR2byJIq57PPcEX0pBiIZEztkAOljdAbhdYcI9Ba8thElmTKzz7/sCAyHQYi0huF1pwj0Fry2ESWZIrPPv+wIDIdBiIioiqOf1gQPTn2MiMiIiLZYyAiIiIi2WMgIiIiItmz6kA0Y8YMKBQKnUeTJk2k7ffv30d0dDRq164NZ2dn9O/fH1lZWTr7SE9PR3h4OBwdHeHh4YGYmBg8ePDA3C+FiIiIrJjVN6pu1qwZduzYIS3XqPG/Kk+cOBFbtmzBhg0b4OLignHjxqFfv37Yv38/AKCoqAjh4eHw8vLCgQMHkJGRgYiICNja2uKjjz4y+2shIiIi62T1gahGjRrw8vLSW3/nzh2sWLECa9aswQsvvAAAiI+PR1BQEA4ePIgOHTpg+/btOH36NHbs2AFPT0+0bt0as2fPxtSpUzFjxgzY2dkZPGZ+fj7y8/OlZY1GUzkvjoiIiKyCVd8yA4CzZ8+ibt26aNCgAQYPHoz09HQAwLFjx1BYWIhu3bpJZZs0aYJ69eohOTkZAJCcnIwWLVrA09NTKhMWFgaNRoPU1NRSjxkXFwcXFxfp4evrW2pZIiJ6UukAfjPwSLdkpUhmrDoQtW/fHgkJCdi6dSuWLl2KixcvolOnTrh79y4yMzNhZ2cHV1dXned4enoiMzMTAJCZmakThoq3F28rTWxsLO7cuSM9rlzhmB5ERJUjHUXaIADBeo+H6xmKyDys+pZZz549pX+3bNkS7du3h5+fH9avXw8HB4dKO65KpYJKpaq0/RMRUbEbUNrk6Y22HehxBYsGzgNwA0A9i9WO5MOqA1FJrq6uaNSoEc6dO4cXX3wRBQUFuH37ts5VoqysLKnNkZeXFw4fPqyzj+JeaIbaJVV96Xj4n0dJnOiRiKxbydG2iczNqm+ZlZSTk4Pz58/D29sbwcHBsLW1RVJSkrQ9LS0N6enpCAkJAQCEhITg1KlTyM7OlsokJiZCrVajadOmZq+/6Ri6374FRdomMHTZGeDEj0RERGWx6itEkydPRu/eveHn54dr165h+vTpUCqVeOONN+Di4oKoqChMmjQJbm5uUKvVeOuttxASEoIOHToAALp3746mTZti6NChmDt3LjIzM/H+++8jOjq6Ct8Se3i/XWmTp7dFaQO9y84AJ3okIiJ6HKsORFevXsUbb7yBv//+G3Xq1EHHjh1x8OBB1KlTBwCwYMEC2NjYoH///sjPz0dYWBiWLFkiPV+pVGLz5s0YO3YsQkJC4OTkhMjISMyaNctSL8kEDN9vLw49hi47c6JHIqLSmhS4g22UCLDyQLR27doyt9vb22Px4sVYvHhxqWX8/Pzw888/m7pqJlbaFzUfQMkrWQ/bA3F2ayKi8ir9ynqR1hFKmzNgKCKrDkTyUNYX1QZKG60F6kREVJ2wJxs9HgORxZV9C6y09UREVDHsyUZlYSCyEqXdAuOtMSIiosrHQERERP9VcswyjmFG8sFAREQkc3Wcb6FIq4DSxhrHLDMUytgzjEyPgYiISObUDjlQ2ggztFk01KPW8FWoskIae4ZRZWAgIiIiAJXdZrH0HrWGlBbS2DOMKgsDERERVQL99khl9agtDXuGkbkwEBERkck8rj2S6a5Cldbgm+2LyDgMREREZDKV3R7pcYGL7YvIWAxERERkcpXVHqm0wAWwfRE9GQYiIiKqcti2iEzNxtIVICIiIrI0BiIiIiKSPQYiIiIikj0GIiIiIpI9NqomIiIyCUNTkwCmGxupsvcvbwxERERET6z0qUlMMzZSZe+fGIiIiIie2A2DU5OYbmykyt4/MRARERGZSGWPj8TxlyoPAxEREVUz+hPLEj0OAxEREVULj5vnjKgsDERERFQtVPbEslS9MRAREVG1YpqJZdnFXW4YiIiIiHSwi3v5lRYcgaoWHhmIiIiIdJiri3tVvwpVenAEql54ZCAiIiIyoHK7uFv6KpQpwpjh4AhUzfGRGIiIiEjmLNFN35IDLZo2jFWXsZEYiIiISJasoZu+ZcIER702hIGIiIhkSe7d9M0TxgxdbcsHoDKw3rJtpxiIiIhI1ireTd/QjzxHw35UWVffirQ2UNpoDay3bCNsBiIiIqJysIZbbKUrLZAZc9XF0L4qtp/HXX2zxtt1DERERETlUNqPPGC522yPC2kVuepS9lUd467elHb1zRobYjMQERERVYChH3PjRsN+cmWFtIpedSltX9Zw9cYcGIiIiIgqXeV27S/7ikvFjm2NV2/MQVaBaPHixfj000+RmZmJVq1a4YsvvkC7du0sXS0iIqqmjG939OQByvRtniwxXpP5yCYQrVu3DpMmTcKyZcvQvn17LFy4EGFhYUhLS4OHh4elq0dERNVQRbv2mzLEmGpYAetuTG46sglE8+fPx6hRozB8+HAAwLJly7BlyxZ88803ePfddy1cOyIiqs7K27W/MsZGqviwApVfJ2ski0BUUFCAY8eOITY2VlpnY2ODbt26ITk5Wa98fn4+8vPzpeU7d+4AADQaTSXULgcA4Ot8DoVu96W1dVRXoNE8+XpT7qsqHZt1sv5js07Wf2zWyXLHzs/LR+H9/62/n1tQZepkzDF8na/i4U9sDgDT/dYW/24LIR5fWMjAX3/9JQCIAwcO6KyPiYkR7dq10ys/ffp0AYAPPvjggw8++KgGjytXrjw2K8jiClFFxcbGYtKkSdKyVqvFzZs3Ubt2bSgUCgvWzPw0Gg18fX1x5coVqNVqS1eHSuD5sW48P9aN58f6Pek5EkLg7t27qFu37mPLyiIQubu7Q6lUIisrS2d9VlYWvLy89MqrVCqoVLrzrLi6ulZmFa2eWq3mfxhWjOfHuvH8WDeeH+v3JOfIxcWlXOVsjNp7FWNnZ4fg4GAkJSVJ67RaLZKSkhASEmLBmhEREZE1kMUVIgCYNGkSIiMj0bZtW7Rr1w4LFy5Ebm6u1OuMiIiI5Es2gej111/H9evXMW3aNGRmZqJ169bYunUrPD09LV01q6ZSqTB9+nS9W4hkHXh+rBvPj3Xj+bF+5jxHCiHK0xeNiIiIqPqSRRsiIiIiorIwEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRDJWP369aFQKPQe0dHRBssnJCTolbW3tzdzreWjqKgIH3zwAfz9/eHg4ICAgADMnj37sZMU7t69G23atIFKpUJgYCASEhLMU2GZMeb87N692+B3LjMz04w1l4+7d+9iwoQJ8PPzg4ODA5599lkcOXKkzOfw+2M+FT0/lf39kc04RKTvyJEjKCoqkpZ///13vPjii3jttddKfY5arUZaWpq0LLe53czpk08+wdKlS7Fy5Uo0a9YMR48exfDhw+Hi4oK3337b4HMuXryI8PBwjBkzBqtXr0ZSUhJGjhwJb29vhIWFmfkVVG/GnJ9iaWlpOtMQeHh4VHZ1ZWnkyJH4/fff8e9//xt169bFqlWr0K1bN5w+fRpPPfWUXnl+f8yrouenWKV9f0wxmzxVD+PHjxcBAQFCq9Ua3B4fHy9cXFzMWykZCw8PFyNGjNBZ169fPzF48OBSnzNlyhTRrFkznXWvv/66CAsLq5Q6ypkx52fXrl0CgLh161Yl147y8vKEUqkUmzdv1lnfpk0b8d577xl8Dr8/5mPM+ans7w9vmREAoKCgAKtWrcKIESPKvOqTk5MDPz8/+Pr64uWXX0ZqaqoZaykvzz77LJKSkvDnn38CAE6cOIF9+/ahZ8+epT4nOTkZ3bp101kXFhaG5OTkSq2rHBlzfoq1bt0a3t7eePHFF7F///7KrqosPXjwAEVFRXq39R0cHLBv3z6Dz+H3x3yMOT/FKuv7w1tmBAD48ccfcfv2bQwbNqzUMo0bN8Y333yDli1b4s6dO/jss8/w7LPPIjU1FT4+PuarrEy8++670Gg0aNKkCZRKJYqKijBnzhwMHjy41OdkZmbqTUfj6ekJjUaDe/fuwcHBobKrLRvGnB9vb28sW7YMbdu2RX5+Pr7++muEhobi0KFDaNOmjRlrX/3VrFkTISEhmD17NoKCguDp6YnvvvsOycnJCAwMNPgcfn/Mx5jzU+nfn0q57kRVTvfu3cVLL71UoecUFBSIgIAA8f7771dSreTtu+++Ez4+PuK7774TJ0+eFN9++61wc3MTCQkJpT6nYcOG4qOPPtJZt2XLFgFA5OXlVXaVZcWY82NI586dxZAhQyqplvJ27tw50blzZwFAKJVK8cwzz4jBgweLJk2aGCzP7495VfT8GGLK7w+vEBEuX76MHTt2YNOmTRV6nq2tLZ5++mmcO3eukmombzExMXj33XcxcOBAAECLFi1w+fJlxMXFITIy0uBzvLy8kJWVpbMuKysLarWaf92amDHnx5B27do99hYBGScgIAB79uxBbm4uNBoNvL298frrr6NBgwYGy/P7Y14VPT+GmPL7wzZEhPj4eHh4eCA8PLxCzysqKsKpU6fg7e1dSTWTt7y8PNjY6H5FlUoltFptqc8JCQlBUlKSzrrExESEhIRUSh3lzJjzY0hKSgq/Q5XMyckJ3t7euHXrFrZt24aXX37ZYDl+fyyjvOfHEJN+f0xynYmqrKKiIlGvXj0xdepUvW1Dhw4V7777rrQ8c+ZMsW3bNnH+/Hlx7NgxMXDgQGFvby9SU1PNWWXZiIyMFE899ZTYvHmzuHjxoti0aZNwd3cXU6ZMkcq8++67YujQodLyhQsXhKOjo4iJiRFnzpwRixcvFkqlUmzdutUSL6FaM+b8LFiwQPz444/i7Nmz4tSpU2L8+PHCxsZG7NixwxIvodrbunWr+OWXX8SFCxfE9u3bRatWrUT79u1FQUGBEILfH0ur6Pmp7O8PA5HMbdu2TQAQaWlpetu6dOkiIiMjpeUJEyaIevXqCTs7O+Hp6Sl69eolfvvtNzPWVl40Go0YP368qFevnrC3txcNGjQQ7733nsjPz5fKREZGii5duug8b9euXaJ169bCzs5ONGjQQMTHx5u34jJhzPn55JNPREBAgLC3txdubm4iNDRU7Ny50wK1l4d169aJBg0aCDs7O+Hl5SWio6PF7du3pe38/lhWRc9PZX9/FEI8ZthbIiIiomqObYiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPb+H47YbkqUn3yEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 11.a\n",
    "\n",
    "train_df[target].plot.hist(bins=73, edgecolor=\"yellow\")\n",
    "plt.title(\"Правостороннее асимметричное распределение 'price'\")\n",
    "\n",
    "np.log(train_df[\"price\"]).to_frame().plot.hist(bins=73, edgecolor=\"yellow\")\n",
    "plt.title(\"Лог-нормальное распределение 'price'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8971e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11.a\n",
    "\n",
    "train_df[\"price_log\"] = np.log(train_df[\"price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f41a79",
   "metadata": {},
   "source": [
    "b. The next trick is outliers. The angle of the linear regression line depends strongly on outliers. And often you should remove these points from !allert! only training data. You should explain why they were removed from the training sample only. We recommend that you do this exercise and compare the results.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcf7ed4",
   "metadata": {},
   "source": [
    ">\\# 11.b  \n",
    "\n",
    " Выбросы удаляются только из обучающих данных для:\n",
    "  1. `Сохранения реалистичности тестовых данных`: тестовые данные, как правило, не имеют нормального распределения и на их основе мы можем наиболее точно оценить модель  \n",
    "  \n",
    "  2. `Предотвращение утечки данных`: если выбросы удалить до разделения данных на тестовую и обучающую выборки, то это приведет к неполноте данных, и, как следствие, к тому, что модель будет хуже предсказывать на реальных значениях  \n",
    "  \n",
    "  3. `Сохранения реальной обучающей способности модели`: если удалить выбросы из теста, то метрики оценки будут завышены\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af2707af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 11.b\n",
    "\n",
    "train_df[\"price_log\"].plot.box(vert=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a2b95903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_outliers(data):\n",
    "    q25 = data.quantile(0.25)\n",
    "    q75 = data.quantile(0.75)\n",
    "    iqr = q75 - q25\n",
    "    \n",
    "    return (q25 - 1.5 * iqr, q75 + 1.5 * iqr)\n",
    "\n",
    "\n",
    "boundaries = calculate_outliers(train_df[\"price_log\"])\n",
    "\n",
    "is_outlier = (train_df[\"price_log\"] < boundaries[0]) | (train_df[\"price_log\"] > boundaries[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d90ce9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1499.000000\n",
       "mean        9.250363\n",
       "std         0.123049\n",
       "min         9.058936\n",
       "25%         9.146868\n",
       "50%         9.210340\n",
       "75%         9.354441\n",
       "max         9.472705\n",
       "Name: price_log, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[is_outlier][\"price_log\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c1528a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[is_outlier, \"price_log\"] = np.full(\n",
    "    len(train_df.loc[is_outlier, \"price_log\"]), \n",
    "    train_df.loc[~is_outlier, \"price_log\"].max()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "354930e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[\"price_log\"].plot.box(vert=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d048a74f",
   "metadata": {},
   "source": [
    "c. It will also be a useful exercise to implement a linear regression algorithm with batch and mini-batch training or analytical solution (as mentioned in 4.1).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b21df8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test MAE'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "736.0358888064825"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Test RMSE'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1070.3850677655678"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Test R2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5460678598954488"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 11.c\n",
    "\n",
    "model = MyLinearRegression(\"analytical\")\n",
    "model.fit(train_df[most_common], train_df[\"price\"])\n",
    "train_predict = model.predict(train_df[most_common])\n",
    "test_predict = model.predict(test_df[most_common])\n",
    "\n",
    "display(\n",
    "    \"Test MAE\", mean_absolute_error(test_df[\"price\"], test_predict),\n",
    "    \"Test RMSE\", root_mean_squared_error(test_df[\"price\"], test_predict),\n",
    "    \"Test R2\", r2_score(test_df[\"price\"], test_predict),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2186a8ea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### __Submission__\n",
    "Save your code in Python JupyterNotebook. Your peer will load it and compare it with the basic solution. Your code should include answers to all mandatory questions. The additional task is up to you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
